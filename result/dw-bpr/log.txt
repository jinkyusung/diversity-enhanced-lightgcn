Folder created at: ./dw-bpr/best_model
Your Device: cuda
Yelp2018

#user = 31668
#item = 38048

#interactions
    (train) 1237259
    (test)  324147
    (total) 1561406

Sparsity = 0.0012958757851778645

Epoch 0
-------------------------------
loss: 0.145647 [ 2048/1237259]
loss: 0.114038 [206848/1237259]
loss: 0.066250 [411648/1237259]
loss: 0.057656 [616448/1237259]
loss: 0.047498 [821248/1237259]
loss: 0.040588 [1026048/1237259]
loss: 0.043130 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0315  
ndcg@20: 0.0258  
diversity: 0.1612  


Epoch 1
-------------------------------
loss: 0.043117 [ 2048/1237259]
loss: 0.040939 [206848/1237259]
loss: 0.043506 [411648/1237259]
loss: 0.041922 [616448/1237259]
loss: 0.045867 [821248/1237259]
loss: 0.039378 [1026048/1237259]
loss: 0.037269 [1230848/1237259]
Epoch 2
-------------------------------
loss: 0.040674 [ 2048/1237259]
loss: 0.041173 [206848/1237259]
loss: 0.040488 [411648/1237259]
loss: 0.037142 [616448/1237259]
loss: 0.036394 [821248/1237259]
loss: 0.038467 [1026048/1237259]
loss: 0.036439 [1230848/1237259]
Epoch 3
-------------------------------
loss: 0.037351 [ 2048/1237259]
loss: 0.037361 [206848/1237259]
loss: 0.037255 [411648/1237259]
loss: 0.036430 [616448/1237259]
loss: 0.036981 [821248/1237259]
loss: 0.033180 [1026048/1237259]
loss: 0.043468 [1230848/1237259]
Epoch 4
-------------------------------
loss: 0.034211 [ 2048/1237259]
loss: 0.036899 [206848/1237259]
loss: 0.033532 [411648/1237259]
loss: 0.036190 [616448/1237259]
loss: 0.035503 [821248/1237259]
loss: 0.034242 [1026048/1237259]
loss: 0.032271 [1230848/1237259]
Epoch 5
-------------------------------
loss: 0.034256 [ 2048/1237259]
loss: 0.035148 [206848/1237259]
loss: 0.035669 [411648/1237259]
loss: 0.037790 [616448/1237259]
loss: 0.037598 [821248/1237259]
loss: 0.036310 [1026048/1237259]
loss: 0.033009 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0355  
ndcg@20: 0.0288  
diversity: 0.1627  


Epoch 6
-------------------------------
loss: 0.033366 [ 2048/1237259]
loss: 0.037675 [206848/1237259]
loss: 0.033024 [411648/1237259]
loss: 0.032818 [616448/1237259]
loss: 0.036189 [821248/1237259]
loss: 0.030970 [1026048/1237259]
loss: 0.033270 [1230848/1237259]
Epoch 7
-------------------------------
loss: 0.032407 [ 2048/1237259]
loss: 0.033937 [206848/1237259]
loss: 0.031135 [411648/1237259]
loss: 0.031192 [616448/1237259]
loss: 0.037600 [821248/1237259]
loss: 0.033520 [1026048/1237259]
loss: 0.031815 [1230848/1237259]
Epoch 8
-------------------------------
loss: 0.030084 [ 2048/1237259]
loss: 0.032732 [206848/1237259]
loss: 0.033333 [411648/1237259]
loss: 0.033011 [616448/1237259]
loss: 0.030858 [821248/1237259]
loss: 0.031926 [1026048/1237259]
loss: 0.031669 [1230848/1237259]
Epoch 9
-------------------------------
loss: 0.032052 [ 2048/1237259]
loss: 0.029664 [206848/1237259]
loss: 0.030334 [411648/1237259]
loss: 0.031466 [616448/1237259]
loss: 0.028901 [821248/1237259]
loss: 0.030326 [1026048/1237259]
loss: 0.027866 [1230848/1237259]
Epoch 10
-------------------------------
loss: 0.026234 [ 2048/1237259]
loss: 0.029315 [206848/1237259]
loss: 0.024776 [411648/1237259]
loss: 0.030556 [616448/1237259]
loss: 0.028337 [821248/1237259]
loss: 0.031467 [1026048/1237259]
loss: 0.028375 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0397  
ndcg@20: 0.0320  
diversity: 0.1653  


Epoch 11
-------------------------------
loss: 0.030169 [ 2048/1237259]
loss: 0.029596 [206848/1237259]
loss: 0.026843 [411648/1237259]
loss: 0.029090 [616448/1237259]
loss: 0.027936 [821248/1237259]
loss: 0.027244 [1026048/1237259]
loss: 0.025190 [1230848/1237259]
Epoch 12
-------------------------------
loss: 0.026918 [ 2048/1237259]
loss: 0.026792 [206848/1237259]
loss: 0.027290 [411648/1237259]
loss: 0.025140 [616448/1237259]
loss: 0.028062 [821248/1237259]
loss: 0.023121 [1026048/1237259]
loss: 0.026909 [1230848/1237259]
Epoch 13
-------------------------------
loss: 0.028065 [ 2048/1237259]
loss: 0.029560 [206848/1237259]
loss: 0.027610 [411648/1237259]
loss: 0.028839 [616448/1237259]
loss: 0.026309 [821248/1237259]
loss: 0.025493 [1026048/1237259]
loss: 0.026511 [1230848/1237259]
Epoch 14
-------------------------------
loss: 0.027694 [ 2048/1237259]
loss: 0.025158 [206848/1237259]
loss: 0.030121 [411648/1237259]
loss: 0.026357 [616448/1237259]
loss: 0.028964 [821248/1237259]
loss: 0.022432 [1026048/1237259]
loss: 0.025719 [1230848/1237259]
Epoch 15
-------------------------------
loss: 0.025759 [ 2048/1237259]
loss: 0.029250 [206848/1237259]
loss: 0.026286 [411648/1237259]
loss: 0.025866 [616448/1237259]
loss: 0.028252 [821248/1237259]
loss: 0.027818 [1026048/1237259]
loss: 0.027879 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0412  
ndcg@20: 0.0333  
diversity: 0.1671  


Epoch 16
-------------------------------
loss: 0.026355 [ 2048/1237259]
loss: 0.022687 [206848/1237259]
loss: 0.025290 [411648/1237259]
loss: 0.028956 [616448/1237259]
loss: 0.025936 [821248/1237259]
loss: 0.030026 [1026048/1237259]
loss: 0.024441 [1230848/1237259]
Epoch 17
-------------------------------
loss: 0.028887 [ 2048/1237259]
loss: 0.027032 [206848/1237259]
loss: 0.026452 [411648/1237259]
loss: 0.025205 [616448/1237259]
loss: 0.023685 [821248/1237259]
loss: 0.024757 [1026048/1237259]
loss: 0.024912 [1230848/1237259]
Epoch 18
-------------------------------
loss: 0.026195 [ 2048/1237259]
loss: 0.025075 [206848/1237259]
loss: 0.022611 [411648/1237259]
loss: 0.026519 [616448/1237259]
loss: 0.022792 [821248/1237259]
loss: 0.026477 [1026048/1237259]
loss: 0.028235 [1230848/1237259]
Epoch 19
-------------------------------
loss: 0.021613 [ 2048/1237259]
loss: 0.027319 [206848/1237259]
loss: 0.025889 [411648/1237259]
loss: 0.026178 [616448/1237259]
loss: 0.022619 [821248/1237259]
loss: 0.022021 [1026048/1237259]
loss: 0.029108 [1230848/1237259]
Epoch 20
-------------------------------
loss: 0.024930 [ 2048/1237259]
loss: 0.022281 [206848/1237259]
loss: 0.022339 [411648/1237259]
loss: 0.024219 [616448/1237259]
loss: 0.023337 [821248/1237259]
loss: 0.023567 [1026048/1237259]
loss: 0.025790 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0420  
ndcg@20: 0.0339  
diversity: 0.1677  


Epoch 21
-------------------------------
loss: 0.021818 [ 2048/1237259]
loss: 0.024281 [206848/1237259]
loss: 0.027311 [411648/1237259]
loss: 0.026686 [616448/1237259]
loss: 0.023837 [821248/1237259]
loss: 0.023563 [1026048/1237259]
loss: 0.025455 [1230848/1237259]
Epoch 22
-------------------------------
loss: 0.024085 [ 2048/1237259]
loss: 0.024522 [206848/1237259]
loss: 0.021548 [411648/1237259]
loss: 0.021836 [616448/1237259]
loss: 0.020020 [821248/1237259]
loss: 0.022850 [1026048/1237259]
loss: 0.023442 [1230848/1237259]
Epoch 23
-------------------------------
loss: 0.022124 [ 2048/1237259]
loss: 0.020246 [206848/1237259]
loss: 0.026937 [411648/1237259]
loss: 0.029097 [616448/1237259]
loss: 0.023919 [821248/1237259]
loss: 0.023212 [1026048/1237259]
loss: 0.024326 [1230848/1237259]
Epoch 24
-------------------------------
loss: 0.022426 [ 2048/1237259]
loss: 0.023516 [206848/1237259]
loss: 0.024726 [411648/1237259]
loss: 0.020223 [616448/1237259]
loss: 0.022790 [821248/1237259]
loss: 0.023483 [1026048/1237259]
loss: 0.029862 [1230848/1237259]
Epoch 25
-------------------------------
loss: 0.024436 [ 2048/1237259]
loss: 0.023418 [206848/1237259]
loss: 0.021235 [411648/1237259]
loss: 0.022062 [616448/1237259]
loss: 0.023370 [821248/1237259]
loss: 0.022928 [1026048/1237259]
loss: 0.021472 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0435  
ndcg@20: 0.0351  
diversity: 0.1683  


Epoch 26
-------------------------------
loss: 0.025076 [ 2048/1237259]
loss: 0.019892 [206848/1237259]
loss: 0.024484 [411648/1237259]
loss: 0.021511 [616448/1237259]
loss: 0.023207 [821248/1237259]
loss: 0.021594 [1026048/1237259]
loss: 0.023361 [1230848/1237259]
Epoch 27
-------------------------------
loss: 0.024365 [ 2048/1237259]
loss: 0.021392 [206848/1237259]
loss: 0.024307 [411648/1237259]
loss: 0.022060 [616448/1237259]
loss: 0.020589 [821248/1237259]
loss: 0.020476 [1026048/1237259]
loss: 0.025582 [1230848/1237259]
Epoch 28
-------------------------------
loss: 0.022955 [ 2048/1237259]
loss: 0.021824 [206848/1237259]
loss: 0.023898 [411648/1237259]
loss: 0.020326 [616448/1237259]
loss: 0.023134 [821248/1237259]
loss: 0.020042 [1026048/1237259]
loss: 0.023401 [1230848/1237259]
Epoch 29
-------------------------------
loss: 0.023965 [ 2048/1237259]
loss: 0.021461 [206848/1237259]
loss: 0.023566 [411648/1237259]
loss: 0.020614 [616448/1237259]
loss: 0.024214 [821248/1237259]
loss: 0.022259 [1026048/1237259]
loss: 0.024400 [1230848/1237259]
Epoch 30
-------------------------------
loss: 0.020602 [ 2048/1237259]
loss: 0.020983 [206848/1237259]
loss: 0.020423 [411648/1237259]
loss: 0.021070 [616448/1237259]
loss: 0.021632 [821248/1237259]
loss: 0.022008 [1026048/1237259]
loss: 0.024576 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0443  
ndcg@20: 0.0361  
diversity: 0.1694  


Epoch 31
-------------------------------
loss: 0.021787 [ 2048/1237259]
loss: 0.021926 [206848/1237259]
loss: 0.022144 [411648/1237259]
loss: 0.023920 [616448/1237259]
loss: 0.022227 [821248/1237259]
loss: 0.022570 [1026048/1237259]
loss: 0.021421 [1230848/1237259]
Epoch 32
-------------------------------
loss: 0.018641 [ 2048/1237259]
loss: 0.022155 [206848/1237259]
loss: 0.018673 [411648/1237259]
loss: 0.021177 [616448/1237259]
loss: 0.022199 [821248/1237259]
loss: 0.019943 [1026048/1237259]
loss: 0.023886 [1230848/1237259]
Epoch 33
-------------------------------
loss: 0.018625 [ 2048/1237259]
loss: 0.018890 [206848/1237259]
loss: 0.019486 [411648/1237259]
loss: 0.019686 [616448/1237259]
loss: 0.019669 [821248/1237259]
loss: 0.021125 [1026048/1237259]
loss: 0.017689 [1230848/1237259]
Epoch 34
-------------------------------
loss: 0.019025 [ 2048/1237259]
loss: 0.021472 [206848/1237259]
loss: 0.019555 [411648/1237259]
loss: 0.024103 [616448/1237259]
loss: 0.021413 [821248/1237259]
loss: 0.018750 [1026048/1237259]
loss: 0.020292 [1230848/1237259]
Epoch 35
-------------------------------
loss: 0.020071 [ 2048/1237259]
loss: 0.021058 [206848/1237259]
loss: 0.018226 [411648/1237259]
loss: 0.022429 [616448/1237259]
loss: 0.019790 [821248/1237259]
loss: 0.020624 [1026048/1237259]
loss: 0.019902 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0453  
ndcg@20: 0.0369  
diversity: 0.1702  


Epoch 36
-------------------------------
loss: 0.021680 [ 2048/1237259]
loss: 0.021556 [206848/1237259]
loss: 0.019009 [411648/1237259]
loss: 0.018418 [616448/1237259]
loss: 0.019879 [821248/1237259]
loss: 0.021315 [1026048/1237259]
loss: 0.018874 [1230848/1237259]
Epoch 37
-------------------------------
loss: 0.015294 [ 2048/1237259]
loss: 0.014258 [206848/1237259]
loss: 0.022570 [411648/1237259]
loss: 0.018662 [616448/1237259]
loss: 0.019270 [821248/1237259]
loss: 0.021884 [1026048/1237259]
loss: 0.021941 [1230848/1237259]
Epoch 38
-------------------------------
loss: 0.021407 [ 2048/1237259]
loss: 0.021961 [206848/1237259]
loss: 0.020936 [411648/1237259]
loss: 0.022222 [616448/1237259]
loss: 0.018664 [821248/1237259]
loss: 0.017172 [1026048/1237259]
loss: 0.019196 [1230848/1237259]
Epoch 39
-------------------------------
loss: 0.023544 [ 2048/1237259]
loss: 0.018435 [206848/1237259]
loss: 0.018838 [411648/1237259]
loss: 0.018951 [616448/1237259]
loss: 0.021260 [821248/1237259]
loss: 0.020771 [1026048/1237259]
loss: 0.017055 [1230848/1237259]
Epoch 40
-------------------------------
loss: 0.021305 [ 2048/1237259]
loss: 0.021410 [206848/1237259]
loss: 0.021610 [411648/1237259]
loss: 0.019591 [616448/1237259]
loss: 0.019708 [821248/1237259]
loss: 0.019431 [1026048/1237259]
loss: 0.020881 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0460  
ndcg@20: 0.0375  
diversity: 0.1709  


Epoch 41
-------------------------------
loss: 0.016739 [ 2048/1237259]
loss: 0.018553 [206848/1237259]
loss: 0.020991 [411648/1237259]
loss: 0.020009 [616448/1237259]
loss: 0.019318 [821248/1237259]
loss: 0.021012 [1026048/1237259]
loss: 0.017567 [1230848/1237259]
Epoch 42
-------------------------------
loss: 0.019653 [ 2048/1237259]
loss: 0.022046 [206848/1237259]
loss: 0.019330 [411648/1237259]
loss: 0.018267 [616448/1237259]
loss: 0.020463 [821248/1237259]
loss: 0.018823 [1026048/1237259]
loss: 0.018331 [1230848/1237259]
Epoch 43
-------------------------------
loss: 0.019011 [ 2048/1237259]
loss: 0.020105 [206848/1237259]
loss: 0.020539 [411648/1237259]
loss: 0.020122 [616448/1237259]
loss: 0.021076 [821248/1237259]
loss: 0.020423 [1026048/1237259]
loss: 0.020101 [1230848/1237259]
Epoch 44
-------------------------------
loss: 0.016994 [ 2048/1237259]
loss: 0.017755 [206848/1237259]
loss: 0.019813 [411648/1237259]
loss: 0.019830 [616448/1237259]
loss: 0.018680 [821248/1237259]
loss: 0.016614 [1026048/1237259]
loss: 0.022672 [1230848/1237259]
Epoch 45
-------------------------------
loss: 0.019710 [ 2048/1237259]
loss: 0.020976 [206848/1237259]
loss: 0.019979 [411648/1237259]
loss: 0.018318 [616448/1237259]
loss: 0.018551 [821248/1237259]
loss: 0.016336 [1026048/1237259]
loss: 0.021192 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0466  
ndcg@20: 0.0381  
diversity: 0.1716  


Epoch 46
-------------------------------
loss: 0.019105 [ 2048/1237259]
loss: 0.017321 [206848/1237259]
loss: 0.017077 [411648/1237259]
loss: 0.021468 [616448/1237259]
loss: 0.018780 [821248/1237259]
loss: 0.019413 [1026048/1237259]
loss: 0.018679 [1230848/1237259]
Epoch 47
-------------------------------
loss: 0.021302 [ 2048/1237259]
loss: 0.018812 [206848/1237259]
loss: 0.019160 [411648/1237259]
loss: 0.019631 [616448/1237259]
loss: 0.017686 [821248/1237259]
loss: 0.020167 [1026048/1237259]
loss: 0.020664 [1230848/1237259]
Epoch 48
-------------------------------
loss: 0.017243 [ 2048/1237259]
loss: 0.020138 [206848/1237259]
loss: 0.019908 [411648/1237259]
loss: 0.017242 [616448/1237259]
loss: 0.021789 [821248/1237259]
loss: 0.017267 [1026048/1237259]
loss: 0.018787 [1230848/1237259]
Epoch 49
-------------------------------
loss: 0.017973 [ 2048/1237259]
loss: 0.016728 [206848/1237259]
loss: 0.017416 [411648/1237259]
loss: 0.020055 [616448/1237259]
loss: 0.019447 [821248/1237259]
loss: 0.017411 [1026048/1237259]
loss: 0.019068 [1230848/1237259]
Epoch 50
-------------------------------
loss: 0.017723 [ 2048/1237259]
loss: 0.018107 [206848/1237259]
loss: 0.018238 [411648/1237259]
loss: 0.019217 [616448/1237259]
loss: 0.017248 [821248/1237259]
loss: 0.018276 [1026048/1237259]
loss: 0.017886 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0473  
ndcg@20: 0.0385  
diversity: 0.1720  


Epoch 51
-------------------------------
loss: 0.017631 [ 2048/1237259]
loss: 0.019379 [206848/1237259]
loss: 0.018994 [411648/1237259]
loss: 0.019238 [616448/1237259]
loss: 0.021254 [821248/1237259]
loss: 0.015345 [1026048/1237259]
loss: 0.017540 [1230848/1237259]
Epoch 52
-------------------------------
loss: 0.016587 [ 2048/1237259]
loss: 0.015582 [206848/1237259]
loss: 0.016400 [411648/1237259]
loss: 0.018939 [616448/1237259]
loss: 0.019406 [821248/1237259]
loss: 0.020541 [1026048/1237259]
loss: 0.016783 [1230848/1237259]
Epoch 53
-------------------------------
loss: 0.017416 [ 2048/1237259]
loss: 0.017735 [206848/1237259]
loss: 0.017777 [411648/1237259]
loss: 0.015759 [616448/1237259]
loss: 0.018336 [821248/1237259]
loss: 0.016411 [1026048/1237259]
loss: 0.017756 [1230848/1237259]
Epoch 54
-------------------------------
loss: 0.017001 [ 2048/1237259]
loss: 0.017001 [206848/1237259]
loss: 0.015079 [411648/1237259]
loss: 0.018517 [616448/1237259]
loss: 0.019108 [821248/1237259]
loss: 0.018143 [1026048/1237259]
loss: 0.017797 [1230848/1237259]
Epoch 55
-------------------------------
loss: 0.018291 [ 2048/1237259]
loss: 0.019465 [206848/1237259]
loss: 0.017782 [411648/1237259]
loss: 0.016948 [616448/1237259]
loss: 0.017775 [821248/1237259]
loss: 0.020511 [1026048/1237259]
loss: 0.017760 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0480  
ndcg@20: 0.0391  
diversity: 0.1725  


Epoch 56
-------------------------------
loss: 0.016436 [ 2048/1237259]
loss: 0.017679 [206848/1237259]
loss: 0.018108 [411648/1237259]
loss: 0.017790 [616448/1237259]
loss: 0.015949 [821248/1237259]
loss: 0.016217 [1026048/1237259]
loss: 0.018733 [1230848/1237259]
Epoch 57
-------------------------------
loss: 0.018358 [ 2048/1237259]
loss: 0.017104 [206848/1237259]
loss: 0.018217 [411648/1237259]
loss: 0.018477 [616448/1237259]
loss: 0.020355 [821248/1237259]
loss: 0.020725 [1026048/1237259]
loss: 0.016372 [1230848/1237259]
Epoch 58
-------------------------------
loss: 0.015878 [ 2048/1237259]
loss: 0.018476 [206848/1237259]
loss: 0.020045 [411648/1237259]
loss: 0.018442 [616448/1237259]
loss: 0.017200 [821248/1237259]
loss: 0.015382 [1026048/1237259]
loss: 0.019640 [1230848/1237259]
Epoch 59
-------------------------------
loss: 0.018434 [ 2048/1237259]
loss: 0.016467 [206848/1237259]
loss: 0.017936 [411648/1237259]
loss: 0.016524 [616448/1237259]
loss: 0.017277 [821248/1237259]
loss: 0.020806 [1026048/1237259]
loss: 0.016303 [1230848/1237259]
Epoch 60
-------------------------------
loss: 0.016862 [ 2048/1237259]
loss: 0.018123 [206848/1237259]
loss: 0.017580 [411648/1237259]
loss: 0.016487 [616448/1237259]
loss: 0.020673 [821248/1237259]
loss: 0.017697 [1026048/1237259]
loss: 0.017522 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0489  
ndcg@20: 0.0397  
diversity: 0.1731  


Epoch 61
-------------------------------
loss: 0.016361 [ 2048/1237259]
loss: 0.016609 [206848/1237259]
loss: 0.018851 [411648/1237259]
loss: 0.015224 [616448/1237259]
loss: 0.017278 [821248/1237259]
loss: 0.018092 [1026048/1237259]
loss: 0.017037 [1230848/1237259]
Epoch 62
-------------------------------
loss: 0.017829 [ 2048/1237259]
loss: 0.016017 [206848/1237259]
loss: 0.018343 [411648/1237259]
loss: 0.015345 [616448/1237259]
loss: 0.020053 [821248/1237259]
loss: 0.016104 [1026048/1237259]
loss: 0.020939 [1230848/1237259]
Epoch 63
-------------------------------
loss: 0.016425 [ 2048/1237259]
loss: 0.016629 [206848/1237259]
loss: 0.018444 [411648/1237259]
loss: 0.016615 [616448/1237259]
loss: 0.017036 [821248/1237259]
loss: 0.020001 [1026048/1237259]
loss: 0.018084 [1230848/1237259]
Epoch 64
-------------------------------
loss: 0.018748 [ 2048/1237259]
loss: 0.016942 [206848/1237259]
loss: 0.018737 [411648/1237259]
loss: 0.019781 [616448/1237259]
loss: 0.019071 [821248/1237259]
loss: 0.018356 [1026048/1237259]
loss: 0.018690 [1230848/1237259]
Epoch 65
-------------------------------
loss: 0.019936 [ 2048/1237259]
loss: 0.017771 [206848/1237259]
loss: 0.016006 [411648/1237259]
loss: 0.018811 [616448/1237259]
loss: 0.018860 [821248/1237259]
loss: 0.019644 [1026048/1237259]
loss: 0.019174 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0496  
ndcg@20: 0.0402  
diversity: 0.1735  


Epoch 66
-------------------------------
loss: 0.018523 [ 2048/1237259]
loss: 0.016485 [206848/1237259]
loss: 0.020059 [411648/1237259]
loss: 0.018772 [616448/1237259]
loss: 0.018232 [821248/1237259]
loss: 0.015200 [1026048/1237259]
loss: 0.017695 [1230848/1237259]
Epoch 67
-------------------------------
loss: 0.015963 [ 2048/1237259]
loss: 0.018028 [206848/1237259]
loss: 0.014531 [411648/1237259]
loss: 0.016031 [616448/1237259]
loss: 0.017078 [821248/1237259]
loss: 0.018743 [1026048/1237259]
loss: 0.017192 [1230848/1237259]
Epoch 68
-------------------------------
loss: 0.015428 [ 2048/1237259]
loss: 0.017413 [206848/1237259]
loss: 0.020122 [411648/1237259]
loss: 0.015633 [616448/1237259]
loss: 0.020436 [821248/1237259]
loss: 0.019452 [1026048/1237259]
loss: 0.014951 [1230848/1237259]
Epoch 69
-------------------------------
loss: 0.018682 [ 2048/1237259]
loss: 0.016148 [206848/1237259]
loss: 0.015586 [411648/1237259]
loss: 0.016026 [616448/1237259]
loss: 0.016735 [821248/1237259]
loss: 0.016844 [1026048/1237259]
loss: 0.018041 [1230848/1237259]
Epoch 70
-------------------------------
loss: 0.018023 [ 2048/1237259]
loss: 0.016081 [206848/1237259]
loss: 0.016769 [411648/1237259]
loss: 0.018683 [616448/1237259]
loss: 0.017752 [821248/1237259]
loss: 0.016544 [1026048/1237259]
loss: 0.017878 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0503  
ndcg@20: 0.0408  
diversity: 0.1741  


Epoch 71
-------------------------------
loss: 0.018507 [ 2048/1237259]
loss: 0.018419 [206848/1237259]
loss: 0.017981 [411648/1237259]
loss: 0.016486 [616448/1237259]
loss: 0.015673 [821248/1237259]
loss: 0.018349 [1026048/1237259]
loss: 0.017685 [1230848/1237259]
Epoch 72
-------------------------------
loss: 0.019568 [ 2048/1237259]
loss: 0.016143 [206848/1237259]
loss: 0.017451 [411648/1237259]
loss: 0.017167 [616448/1237259]
loss: 0.016088 [821248/1237259]
loss: 0.019197 [1026048/1237259]
loss: 0.018172 [1230848/1237259]
Epoch 73
-------------------------------
loss: 0.016303 [ 2048/1237259]
loss: 0.016747 [206848/1237259]
loss: 0.016751 [411648/1237259]
loss: 0.015269 [616448/1237259]
loss: 0.015753 [821248/1237259]
loss: 0.014939 [1026048/1237259]
loss: 0.017770 [1230848/1237259]
Epoch 74
-------------------------------
loss: 0.014855 [ 2048/1237259]
loss: 0.018736 [206848/1237259]
loss: 0.017022 [411648/1237259]
loss: 0.018871 [616448/1237259]
loss: 0.015992 [821248/1237259]
loss: 0.017230 [1026048/1237259]
loss: 0.018078 [1230848/1237259]
Epoch 75
-------------------------------
loss: 0.015599 [ 2048/1237259]
loss: 0.017467 [206848/1237259]
loss: 0.019292 [411648/1237259]
loss: 0.018298 [616448/1237259]
loss: 0.017426 [821248/1237259]
loss: 0.019041 [1026048/1237259]
loss: 0.018167 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0511  
ndcg@20: 0.0413  
diversity: 0.1745  


Epoch 76
-------------------------------
loss: 0.016290 [ 2048/1237259]
loss: 0.016867 [206848/1237259]
loss: 0.019944 [411648/1237259]
loss: 0.016024 [616448/1237259]
loss: 0.015622 [821248/1237259]
loss: 0.016494 [1026048/1237259]
loss: 0.014329 [1230848/1237259]
Epoch 77
-------------------------------
loss: 0.015737 [ 2048/1237259]
loss: 0.018653 [206848/1237259]
loss: 0.017559 [411648/1237259]
loss: 0.016008 [616448/1237259]
loss: 0.017326 [821248/1237259]
loss: 0.016835 [1026048/1237259]
loss: 0.015118 [1230848/1237259]
Epoch 78
-------------------------------
loss: 0.019123 [ 2048/1237259]
loss: 0.016741 [206848/1237259]
loss: 0.015220 [411648/1237259]
loss: 0.016119 [616448/1237259]
loss: 0.016657 [821248/1237259]
loss: 0.016159 [1026048/1237259]
loss: 0.016097 [1230848/1237259]
Epoch 79
-------------------------------
loss: 0.015307 [ 2048/1237259]
loss: 0.015831 [206848/1237259]
loss: 0.019485 [411648/1237259]
loss: 0.016659 [616448/1237259]
loss: 0.016732 [821248/1237259]
loss: 0.017013 [1026048/1237259]
loss: 0.017942 [1230848/1237259]
Epoch 80
-------------------------------
loss: 0.017286 [ 2048/1237259]
loss: 0.017522 [206848/1237259]
loss: 0.017347 [411648/1237259]
loss: 0.017759 [616448/1237259]
loss: 0.016187 [821248/1237259]
loss: 0.016531 [1026048/1237259]
loss: 0.018680 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0518  
ndcg@20: 0.0417  
diversity: 0.1748  


Epoch 81
-------------------------------
loss: 0.017653 [ 2048/1237259]
loss: 0.015052 [206848/1237259]
loss: 0.015486 [411648/1237259]
loss: 0.017434 [616448/1237259]
loss: 0.016374 [821248/1237259]
loss: 0.016391 [1026048/1237259]
loss: 0.015363 [1230848/1237259]
Epoch 82
-------------------------------
loss: 0.015573 [ 2048/1237259]
loss: 0.014313 [206848/1237259]
loss: 0.017134 [411648/1237259]
loss: 0.017037 [616448/1237259]
loss: 0.015135 [821248/1237259]
loss: 0.015785 [1026048/1237259]
loss: 0.014323 [1230848/1237259]
Epoch 83
-------------------------------
loss: 0.016117 [ 2048/1237259]
loss: 0.015518 [206848/1237259]
loss: 0.015115 [411648/1237259]
loss: 0.017522 [616448/1237259]
loss: 0.016469 [821248/1237259]
loss: 0.014575 [1026048/1237259]
loss: 0.017821 [1230848/1237259]
Epoch 84
-------------------------------
loss: 0.016397 [ 2048/1237259]
loss: 0.016608 [206848/1237259]
loss: 0.014910 [411648/1237259]
loss: 0.016960 [616448/1237259]
loss: 0.017625 [821248/1237259]
loss: 0.016912 [1026048/1237259]
loss: 0.017684 [1230848/1237259]
Epoch 85
-------------------------------
loss: 0.013554 [ 2048/1237259]
loss: 0.018395 [206848/1237259]
loss: 0.018575 [411648/1237259]
loss: 0.017889 [616448/1237259]
loss: 0.017177 [821248/1237259]
loss: 0.013507 [1026048/1237259]
loss: 0.016860 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0523  
ndcg@20: 0.0421  
diversity: 0.1752  


Epoch 86
-------------------------------
loss: 0.017442 [ 2048/1237259]
loss: 0.017072 [206848/1237259]
loss: 0.017255 [411648/1237259]
loss: 0.016605 [616448/1237259]
loss: 0.018065 [821248/1237259]
loss: 0.018586 [1026048/1237259]
loss: 0.016208 [1230848/1237259]
Epoch 87
-------------------------------
loss: 0.015075 [ 2048/1237259]
loss: 0.014852 [206848/1237259]
loss: 0.015772 [411648/1237259]
loss: 0.013867 [616448/1237259]
loss: 0.018986 [821248/1237259]
loss: 0.015226 [1026048/1237259]
loss: 0.014487 [1230848/1237259]
Epoch 88
-------------------------------
loss: 0.014330 [ 2048/1237259]
loss: 0.018039 [206848/1237259]
loss: 0.015608 [411648/1237259]
loss: 0.018679 [616448/1237259]
loss: 0.017990 [821248/1237259]
loss: 0.017042 [1026048/1237259]
loss: 0.016432 [1230848/1237259]
Epoch 89
-------------------------------
loss: 0.016205 [ 2048/1237259]
loss: 0.017606 [206848/1237259]
loss: 0.016895 [411648/1237259]
loss: 0.016003 [616448/1237259]
loss: 0.015999 [821248/1237259]
loss: 0.017368 [1026048/1237259]
loss: 0.014604 [1230848/1237259]
Epoch 90
-------------------------------
loss: 0.014759 [ 2048/1237259]
loss: 0.016917 [206848/1237259]
loss: 0.016811 [411648/1237259]
loss: 0.018140 [616448/1237259]
loss: 0.012737 [821248/1237259]
loss: 0.015141 [1026048/1237259]
loss: 0.016965 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0528  
ndcg@20: 0.0425  
diversity: 0.1756  


Epoch 91
-------------------------------
loss: 0.016152 [ 2048/1237259]
loss: 0.015231 [206848/1237259]
loss: 0.015410 [411648/1237259]
loss: 0.015482 [616448/1237259]
loss: 0.018368 [821248/1237259]
loss: 0.015748 [1026048/1237259]
loss: 0.017657 [1230848/1237259]
Epoch 92
-------------------------------
loss: 0.014399 [ 2048/1237259]
loss: 0.015338 [206848/1237259]
loss: 0.016076 [411648/1237259]
loss: 0.015389 [616448/1237259]
loss: 0.017957 [821248/1237259]
loss: 0.015770 [1026048/1237259]
loss: 0.015937 [1230848/1237259]
Epoch 93
-------------------------------
loss: 0.015180 [ 2048/1237259]
loss: 0.014915 [206848/1237259]
loss: 0.014152 [411648/1237259]
loss: 0.015262 [616448/1237259]
loss: 0.017287 [821248/1237259]
loss: 0.016954 [1026048/1237259]
loss: 0.013553 [1230848/1237259]
Epoch 94
-------------------------------
loss: 0.016397 [ 2048/1237259]
loss: 0.016875 [206848/1237259]
loss: 0.014187 [411648/1237259]
loss: 0.016088 [616448/1237259]
loss: 0.013832 [821248/1237259]
loss: 0.014325 [1026048/1237259]
loss: 0.015205 [1230848/1237259]
Epoch 95
-------------------------------
loss: 0.013837 [ 2048/1237259]
loss: 0.015823 [206848/1237259]
loss: 0.016253 [411648/1237259]
loss: 0.016482 [616448/1237259]
loss: 0.014851 [821248/1237259]
loss: 0.016166 [1026048/1237259]
loss: 0.014946 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0531  
ndcg@20: 0.0427  
diversity: 0.1760  


Epoch 96
-------------------------------
loss: 0.015833 [ 2048/1237259]
loss: 0.016213 [206848/1237259]
loss: 0.017069 [411648/1237259]
loss: 0.016262 [616448/1237259]
loss: 0.018235 [821248/1237259]
loss: 0.014213 [1026048/1237259]
loss: 0.016341 [1230848/1237259]
Epoch 97
-------------------------------
loss: 0.014773 [ 2048/1237259]
loss: 0.016377 [206848/1237259]
loss: 0.013916 [411648/1237259]
loss: 0.014997 [616448/1237259]
loss: 0.017658 [821248/1237259]
loss: 0.017767 [1026048/1237259]
loss: 0.019956 [1230848/1237259]
Epoch 98
-------------------------------
loss: 0.018194 [ 2048/1237259]
loss: 0.016463 [206848/1237259]
loss: 0.016499 [411648/1237259]
loss: 0.014412 [616448/1237259]
loss: 0.015369 [821248/1237259]
loss: 0.014861 [1026048/1237259]
loss: 0.016277 [1230848/1237259]
Epoch 99
-------------------------------
loss: 0.016960 [ 2048/1237259]
loss: 0.015505 [206848/1237259]
loss: 0.015566 [411648/1237259]
loss: 0.015885 [616448/1237259]
loss: 0.016669 [821248/1237259]
loss: 0.015622 [1026048/1237259]
loss: 0.016614 [1230848/1237259]
Epoch 100
-------------------------------
loss: 0.013478 [ 2048/1237259]
loss: 0.015319 [206848/1237259]
loss: 0.016374 [411648/1237259]
loss: 0.014587 [616448/1237259]
loss: 0.014135 [821248/1237259]
loss: 0.014968 [1026048/1237259]
loss: 0.016573 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0536  
ndcg@20: 0.0433  
diversity: 0.1763  


Epoch 101
-------------------------------
loss: 0.014723 [ 2048/1237259]
loss: 0.016179 [206848/1237259]
loss: 0.016177 [411648/1237259]
loss: 0.016200 [616448/1237259]
loss: 0.013450 [821248/1237259]
loss: 0.013602 [1026048/1237259]
loss: 0.016985 [1230848/1237259]
Epoch 102
-------------------------------
loss: 0.016266 [ 2048/1237259]
loss: 0.015761 [206848/1237259]
loss: 0.013761 [411648/1237259]
loss: 0.017390 [616448/1237259]
loss: 0.015368 [821248/1237259]
loss: 0.015250 [1026048/1237259]
loss: 0.016392 [1230848/1237259]
Epoch 103
-------------------------------
loss: 0.015092 [ 2048/1237259]
loss: 0.014903 [206848/1237259]
loss: 0.015772 [411648/1237259]
loss: 0.015860 [616448/1237259]
loss: 0.019540 [821248/1237259]
loss: 0.014598 [1026048/1237259]
loss: 0.015636 [1230848/1237259]
Epoch 104
-------------------------------
loss: 0.016647 [ 2048/1237259]
loss: 0.016240 [206848/1237259]
loss: 0.014147 [411648/1237259]
loss: 0.015818 [616448/1237259]
loss: 0.015194 [821248/1237259]
loss: 0.016536 [1026048/1237259]
loss: 0.017731 [1230848/1237259]
Epoch 105
-------------------------------
loss: 0.015738 [ 2048/1237259]
loss: 0.013617 [206848/1237259]
loss: 0.013797 [411648/1237259]
loss: 0.014767 [616448/1237259]
loss: 0.016981 [821248/1237259]
loss: 0.015530 [1026048/1237259]
loss: 0.015442 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0537  
ndcg@20: 0.0434  
diversity: 0.1766  


Epoch 106
-------------------------------
loss: 0.015696 [ 2048/1237259]
loss: 0.014793 [206848/1237259]
loss: 0.014673 [411648/1237259]
loss: 0.014435 [616448/1237259]
loss: 0.015913 [821248/1237259]
loss: 0.014329 [1026048/1237259]
loss: 0.015935 [1230848/1237259]
Epoch 107
-------------------------------
loss: 0.016353 [ 2048/1237259]
loss: 0.014239 [206848/1237259]
loss: 0.016326 [411648/1237259]
loss: 0.016309 [616448/1237259]
loss: 0.014968 [821248/1237259]
loss: 0.018046 [1026048/1237259]
loss: 0.015676 [1230848/1237259]
Epoch 108
-------------------------------
loss: 0.017132 [ 2048/1237259]
loss: 0.016637 [206848/1237259]
loss: 0.014796 [411648/1237259]
loss: 0.018918 [616448/1237259]
loss: 0.016262 [821248/1237259]
loss: 0.015923 [1026048/1237259]
loss: 0.017246 [1230848/1237259]
Epoch 109
-------------------------------
loss: 0.014333 [ 2048/1237259]
loss: 0.016456 [206848/1237259]
loss: 0.015700 [411648/1237259]
loss: 0.014477 [616448/1237259]
loss: 0.019360 [821248/1237259]
loss: 0.015129 [1026048/1237259]
loss: 0.015440 [1230848/1237259]
Epoch 110
-------------------------------
loss: 0.015938 [ 2048/1237259]
loss: 0.015899 [206848/1237259]
loss: 0.015412 [411648/1237259]
loss: 0.015256 [616448/1237259]
loss: 0.017138 [821248/1237259]
loss: 0.017497 [1026048/1237259]
loss: 0.017145 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0539  
ndcg@20: 0.0435  
diversity: 0.1769  


Epoch 111
-------------------------------
loss: 0.013679 [ 2048/1237259]
loss: 0.016680 [206848/1237259]
loss: 0.016418 [411648/1237259]
loss: 0.013661 [616448/1237259]
loss: 0.014625 [821248/1237259]
loss: 0.015774 [1026048/1237259]
loss: 0.013789 [1230848/1237259]
Epoch 112
-------------------------------
loss: 0.013996 [ 2048/1237259]
loss: 0.016094 [206848/1237259]
loss: 0.016424 [411648/1237259]
loss: 0.016110 [616448/1237259]
loss: 0.016276 [821248/1237259]
loss: 0.016646 [1026048/1237259]
loss: 0.016292 [1230848/1237259]
Epoch 113
-------------------------------
loss: 0.015491 [ 2048/1237259]
loss: 0.015325 [206848/1237259]
loss: 0.015589 [411648/1237259]
loss: 0.016125 [616448/1237259]
loss: 0.015178 [821248/1237259]
loss: 0.016245 [1026048/1237259]
loss: 0.013221 [1230848/1237259]
Epoch 114
-------------------------------
loss: 0.014431 [ 2048/1237259]
loss: 0.014372 [206848/1237259]
loss: 0.014271 [411648/1237259]
loss: 0.014516 [616448/1237259]
loss: 0.015678 [821248/1237259]
loss: 0.015042 [1026048/1237259]
loss: 0.016002 [1230848/1237259]
Epoch 115
-------------------------------
loss: 0.014047 [ 2048/1237259]
loss: 0.016540 [206848/1237259]
loss: 0.014291 [411648/1237259]
loss: 0.014177 [616448/1237259]
loss: 0.015281 [821248/1237259]
loss: 0.016160 [1026048/1237259]
loss: 0.014142 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0545  
ndcg@20: 0.0439  
diversity: 0.1772  


Epoch 116
-------------------------------
loss: 0.015982 [ 2048/1237259]
loss: 0.017254 [206848/1237259]
loss: 0.015710 [411648/1237259]
loss: 0.017191 [616448/1237259]
loss: 0.014891 [821248/1237259]
loss: 0.015040 [1026048/1237259]
loss: 0.016670 [1230848/1237259]
Epoch 117
-------------------------------
loss: 0.013537 [ 2048/1237259]
loss: 0.013303 [206848/1237259]
loss: 0.016685 [411648/1237259]
loss: 0.017428 [616448/1237259]
loss: 0.014837 [821248/1237259]
loss: 0.014657 [1026048/1237259]
loss: 0.014299 [1230848/1237259]
Epoch 118
-------------------------------
loss: 0.016119 [ 2048/1237259]
loss: 0.013157 [206848/1237259]
loss: 0.015397 [411648/1237259]
loss: 0.014900 [616448/1237259]
loss: 0.015932 [821248/1237259]
loss: 0.015334 [1026048/1237259]
loss: 0.015512 [1230848/1237259]
Epoch 119
-------------------------------
loss: 0.014745 [ 2048/1237259]
loss: 0.014619 [206848/1237259]
loss: 0.015301 [411648/1237259]
loss: 0.015942 [616448/1237259]
loss: 0.016252 [821248/1237259]
loss: 0.013445 [1026048/1237259]
loss: 0.015063 [1230848/1237259]
Epoch 120
-------------------------------
loss: 0.015008 [ 2048/1237259]
loss: 0.017032 [206848/1237259]
loss: 0.014775 [411648/1237259]
loss: 0.017089 [616448/1237259]
loss: 0.015638 [821248/1237259]
loss: 0.013112 [1026048/1237259]
loss: 0.013529 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0548  
ndcg@20: 0.0440  
diversity: 0.1774  


Epoch 121
-------------------------------
loss: 0.016837 [ 2048/1237259]
loss: 0.015491 [206848/1237259]
loss: 0.015320 [411648/1237259]
loss: 0.014369 [616448/1237259]
loss: 0.016839 [821248/1237259]
loss: 0.014745 [1026048/1237259]
loss: 0.015654 [1230848/1237259]
Epoch 122
-------------------------------
loss: 0.014325 [ 2048/1237259]
loss: 0.016132 [206848/1237259]
loss: 0.013542 [411648/1237259]
loss: 0.014417 [616448/1237259]
loss: 0.013497 [821248/1237259]
loss: 0.016205 [1026048/1237259]
loss: 0.012276 [1230848/1237259]
Epoch 123
-------------------------------
loss: 0.015056 [ 2048/1237259]
loss: 0.014381 [206848/1237259]
loss: 0.015207 [411648/1237259]
loss: 0.014303 [616448/1237259]
loss: 0.013971 [821248/1237259]
loss: 0.016232 [1026048/1237259]
loss: 0.014569 [1230848/1237259]
Epoch 124
-------------------------------
loss: 0.014067 [ 2048/1237259]
loss: 0.015914 [206848/1237259]
loss: 0.014131 [411648/1237259]
loss: 0.015804 [616448/1237259]
loss: 0.015475 [821248/1237259]
loss: 0.015867 [1026048/1237259]
loss: 0.015846 [1230848/1237259]
Epoch 125
-------------------------------
loss: 0.016596 [ 2048/1237259]
loss: 0.014635 [206848/1237259]
loss: 0.013720 [411648/1237259]
loss: 0.016292 [616448/1237259]
loss: 0.013723 [821248/1237259]
loss: 0.015451 [1026048/1237259]
loss: 0.014665 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0549  
ndcg@20: 0.0443  
diversity: 0.1776  


Epoch 126
-------------------------------
loss: 0.015939 [ 2048/1237259]
loss: 0.012961 [206848/1237259]
loss: 0.013540 [411648/1237259]
loss: 0.015361 [616448/1237259]
loss: 0.014329 [821248/1237259]
loss: 0.015186 [1026048/1237259]
loss: 0.016797 [1230848/1237259]
Epoch 127
-------------------------------
loss: 0.014557 [ 2048/1237259]
loss: 0.014511 [206848/1237259]
loss: 0.015518 [411648/1237259]
loss: 0.014061 [616448/1237259]
loss: 0.014160 [821248/1237259]
loss: 0.013328 [1026048/1237259]
loss: 0.015964 [1230848/1237259]
Epoch 128
-------------------------------
loss: 0.014750 [ 2048/1237259]
loss: 0.014127 [206848/1237259]
loss: 0.014149 [411648/1237259]
loss: 0.015382 [616448/1237259]
loss: 0.015924 [821248/1237259]
loss: 0.015643 [1026048/1237259]
loss: 0.016093 [1230848/1237259]
Epoch 129
-------------------------------
loss: 0.014476 [ 2048/1237259]
loss: 0.014700 [206848/1237259]
loss: 0.016137 [411648/1237259]
loss: 0.014456 [616448/1237259]
loss: 0.016712 [821248/1237259]
loss: 0.016124 [1026048/1237259]
loss: 0.017570 [1230848/1237259]
Epoch 130
-------------------------------
loss: 0.014852 [ 2048/1237259]
loss: 0.014467 [206848/1237259]
loss: 0.015061 [411648/1237259]
loss: 0.017891 [616448/1237259]
loss: 0.015834 [821248/1237259]
loss: 0.013652 [1026048/1237259]
loss: 0.016022 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0551  
ndcg@20: 0.0445  
diversity: 0.1780  


Epoch 131
-------------------------------
loss: 0.014501 [ 2048/1237259]
loss: 0.015791 [206848/1237259]
loss: 0.016038 [411648/1237259]
loss: 0.015155 [616448/1237259]
loss: 0.016201 [821248/1237259]
loss: 0.014456 [1026048/1237259]
loss: 0.014409 [1230848/1237259]
Epoch 132
-------------------------------
loss: 0.013484 [ 2048/1237259]
loss: 0.013078 [206848/1237259]
loss: 0.013684 [411648/1237259]
loss: 0.013552 [616448/1237259]
loss: 0.015646 [821248/1237259]
loss: 0.015267 [1026048/1237259]
loss: 0.017277 [1230848/1237259]
Epoch 133
-------------------------------
loss: 0.013791 [ 2048/1237259]
loss: 0.015479 [206848/1237259]
loss: 0.015192 [411648/1237259]
loss: 0.018539 [616448/1237259]
loss: 0.014673 [821248/1237259]
loss: 0.014215 [1026048/1237259]
loss: 0.013267 [1230848/1237259]
Epoch 134
-------------------------------
loss: 0.013031 [ 2048/1237259]
loss: 0.014696 [206848/1237259]
loss: 0.013219 [411648/1237259]
loss: 0.014689 [616448/1237259]
loss: 0.014082 [821248/1237259]
loss: 0.016654 [1026048/1237259]
loss: 0.015395 [1230848/1237259]
Epoch 135
-------------------------------
loss: 0.015913 [ 2048/1237259]
loss: 0.013762 [206848/1237259]
loss: 0.014568 [411648/1237259]
loss: 0.013772 [616448/1237259]
loss: 0.014417 [821248/1237259]
loss: 0.013961 [1026048/1237259]
loss: 0.013773 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0554  
ndcg@20: 0.0447  
diversity: 0.1782  


Epoch 136
-------------------------------
loss: 0.015198 [ 2048/1237259]
loss: 0.014679 [206848/1237259]
loss: 0.013841 [411648/1237259]
loss: 0.014676 [616448/1237259]
loss: 0.014541 [821248/1237259]
loss: 0.015738 [1026048/1237259]
loss: 0.015393 [1230848/1237259]
Epoch 137
-------------------------------
loss: 0.014192 [ 2048/1237259]
loss: 0.014200 [206848/1237259]
loss: 0.014326 [411648/1237259]
loss: 0.014692 [616448/1237259]
loss: 0.017057 [821248/1237259]
loss: 0.017009 [1026048/1237259]
loss: 0.014523 [1230848/1237259]
Epoch 138
-------------------------------
loss: 0.016332 [ 2048/1237259]
loss: 0.014315 [206848/1237259]
loss: 0.015052 [411648/1237259]
loss: 0.015104 [616448/1237259]
loss: 0.016395 [821248/1237259]
loss: 0.015414 [1026048/1237259]
loss: 0.016696 [1230848/1237259]
Epoch 139
-------------------------------
loss: 0.015101 [ 2048/1237259]
loss: 0.015494 [206848/1237259]
loss: 0.015348 [411648/1237259]
loss: 0.015028 [616448/1237259]
loss: 0.013904 [821248/1237259]
loss: 0.014493 [1026048/1237259]
loss: 0.017235 [1230848/1237259]
Epoch 140
-------------------------------
loss: 0.014749 [ 2048/1237259]
loss: 0.016450 [206848/1237259]
loss: 0.012868 [411648/1237259]
loss: 0.017412 [616448/1237259]
loss: 0.014860 [821248/1237259]
loss: 0.014525 [1026048/1237259]
loss: 0.013330 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0555  
ndcg@20: 0.0448  
diversity: 0.1784  


Epoch 141
-------------------------------
loss: 0.014314 [ 2048/1237259]
loss: 0.015047 [206848/1237259]
loss: 0.013484 [411648/1237259]
loss: 0.015168 [616448/1237259]
loss: 0.013372 [821248/1237259]
loss: 0.016000 [1026048/1237259]
loss: 0.015013 [1230848/1237259]
Epoch 142
-------------------------------
loss: 0.014997 [ 2048/1237259]
loss: 0.015309 [206848/1237259]
loss: 0.011763 [411648/1237259]
loss: 0.012735 [616448/1237259]
loss: 0.014679 [821248/1237259]
loss: 0.014067 [1026048/1237259]
loss: 0.012584 [1230848/1237259]
Epoch 143
-------------------------------
loss: 0.013922 [ 2048/1237259]
loss: 0.014565 [206848/1237259]
loss: 0.014964 [411648/1237259]
loss: 0.016295 [616448/1237259]
loss: 0.014857 [821248/1237259]
loss: 0.017054 [1026048/1237259]
loss: 0.014676 [1230848/1237259]
Epoch 144
-------------------------------
loss: 0.013115 [ 2048/1237259]
loss: 0.013400 [206848/1237259]
loss: 0.015117 [411648/1237259]
loss: 0.012742 [616448/1237259]
loss: 0.013605 [821248/1237259]
loss: 0.012758 [1026048/1237259]
loss: 0.012330 [1230848/1237259]
Epoch 145
-------------------------------
loss: 0.014715 [ 2048/1237259]
loss: 0.014640 [206848/1237259]
loss: 0.015408 [411648/1237259]
loss: 0.015738 [616448/1237259]
loss: 0.013074 [821248/1237259]
loss: 0.013165 [1026048/1237259]
loss: 0.017727 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0558  
ndcg@20: 0.0450  
diversity: 0.1787  


Epoch 146
-------------------------------
loss: 0.013489 [ 2048/1237259]
loss: 0.012785 [206848/1237259]
loss: 0.014747 [411648/1237259]
loss: 0.014500 [616448/1237259]
loss: 0.014579 [821248/1237259]
loss: 0.014924 [1026048/1237259]
loss: 0.014271 [1230848/1237259]
Epoch 147
-------------------------------
loss: 0.014345 [ 2048/1237259]
loss: 0.014275 [206848/1237259]
loss: 0.013810 [411648/1237259]
loss: 0.015453 [616448/1237259]
loss: 0.015470 [821248/1237259]
loss: 0.013795 [1026048/1237259]
loss: 0.014065 [1230848/1237259]
Epoch 148
-------------------------------
loss: 0.014011 [ 2048/1237259]
loss: 0.013974 [206848/1237259]
loss: 0.014585 [411648/1237259]
loss: 0.014420 [616448/1237259]
loss: 0.015185 [821248/1237259]
loss: 0.016373 [1026048/1237259]
loss: 0.013177 [1230848/1237259]
Epoch 149
-------------------------------
loss: 0.014096 [ 2048/1237259]
loss: 0.016139 [206848/1237259]
loss: 0.016293 [411648/1237259]
loss: 0.014256 [616448/1237259]
loss: 0.015804 [821248/1237259]
loss: 0.013693 [1026048/1237259]
loss: 0.013400 [1230848/1237259]
Epoch 150
-------------------------------
loss: 0.016167 [ 2048/1237259]
loss: 0.013487 [206848/1237259]
loss: 0.014887 [411648/1237259]
loss: 0.014953 [616448/1237259]
loss: 0.014820 [821248/1237259]
loss: 0.014568 [1026048/1237259]
loss: 0.015085 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0563  
ndcg@20: 0.0454  
diversity: 0.1788  


Epoch 151
-------------------------------
loss: 0.016422 [ 2048/1237259]
loss: 0.013612 [206848/1237259]
loss: 0.013678 [411648/1237259]
loss: 0.012711 [616448/1237259]
loss: 0.014748 [821248/1237259]
loss: 0.015247 [1026048/1237259]
loss: 0.014174 [1230848/1237259]
Epoch 152
-------------------------------
loss: 0.013074 [ 2048/1237259]
loss: 0.012552 [206848/1237259]
loss: 0.014099 [411648/1237259]
loss: 0.013021 [616448/1237259]
loss: 0.015345 [821248/1237259]
loss: 0.014829 [1026048/1237259]
loss: 0.014968 [1230848/1237259]
Epoch 153
-------------------------------
loss: 0.013771 [ 2048/1237259]
loss: 0.013480 [206848/1237259]
loss: 0.016382 [411648/1237259]
loss: 0.014280 [616448/1237259]
loss: 0.013536 [821248/1237259]
loss: 0.013497 [1026048/1237259]
loss: 0.016141 [1230848/1237259]
Epoch 154
-------------------------------
loss: 0.015780 [ 2048/1237259]
loss: 0.014027 [206848/1237259]
loss: 0.015392 [411648/1237259]
loss: 0.013340 [616448/1237259]
loss: 0.015005 [821248/1237259]
loss: 0.015829 [1026048/1237259]
loss: 0.015134 [1230848/1237259]
Epoch 155
-------------------------------
loss: 0.013014 [ 2048/1237259]
loss: 0.015908 [206848/1237259]
loss: 0.014179 [411648/1237259]
loss: 0.013457 [616448/1237259]
loss: 0.016178 [821248/1237259]
loss: 0.012596 [1026048/1237259]
loss: 0.014322 [1230848/1237259]
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0560  
ndcg@20: 0.0452  
diversity: 0.1788  


Epoch 156
-------------------------------
loss: 0.013369 [ 2048/1237259]
loss: 0.014446 [206848/1237259]
loss: 0.014724 [411648/1237259]
loss: 0.015450 [616448/1237259]
loss: 0.014424 [821248/1237259]
loss: 0.013495 [1026048/1237259]
loss: 0.013085 [1230848/1237259]
Epoch 157
-------------------------------
loss: 0.015039 [ 2048/1237259]
loss: 0.015226 [206848/1237259]
loss: 0.015670 [411648/1237259]
loss: 0.014017 [616448/1237259]
loss: 0.013452 [821248/1237259]
loss: 0.014340 [1026048/1237259]
loss: 0.014228 [1230848/1237259]
Epoch 158
-------------------------------
loss: 0.014895 [ 2048/1237259]
loss: 0.013640 [206848/1237259]
loss: 0.014320 [411648/1237259]
loss: 0.012730 [616448/1237259]
loss: 0.012107 [821248/1237259]
loss: 0.013297 [1026048/1237259]
loss: 0.015634 [1230848/1237259]
Epoch 159
-------------------------------
loss: 0.014252 [ 2048/1237259]
loss: 0.015372 [206848/1237259]
loss: 0.012869 [411648/1237259]
loss: 0.015865 [616448/1237259]
loss: 0.012290 [821248/1237259]
loss: 0.012760 [1026048/1237259]
loss: 0.014721 [1230848/1237259]
Epoch 160
-------------------------------
loss: 0.015009 [ 2048/1237259]
loss: 0.013463 [206848/1237259]
loss: 0.013874 [411648/1237259]
loss: 0.013730 [616448/1237259]
loss: 0.016660 [821248/1237259]
loss: 0.015243 [1026048/1237259]
loss: 0.014502 [1230848/1237259]
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0563  
ndcg@20: 0.0455  
diversity: 0.1791  


Epoch 161
-------------------------------
loss: 0.014789 [ 2048/1237259]
loss: 0.014390 [206848/1237259]
loss: 0.013988 [411648/1237259]
loss: 0.015613 [616448/1237259]
loss: 0.014726 [821248/1237259]
loss: 0.013047 [1026048/1237259]
loss: 0.014109 [1230848/1237259]
Epoch 162
-------------------------------
loss: 0.015303 [ 2048/1237259]
loss: 0.015071 [206848/1237259]
loss: 0.012834 [411648/1237259]
loss: 0.015262 [616448/1237259]
loss: 0.014093 [821248/1237259]
loss: 0.015314 [1026048/1237259]
loss: 0.015762 [1230848/1237259]
Epoch 163
-------------------------------
loss: 0.015432 [ 2048/1237259]
loss: 0.014343 [206848/1237259]
loss: 0.013762 [411648/1237259]
loss: 0.014458 [616448/1237259]
loss: 0.014366 [821248/1237259]
loss: 0.015513 [1026048/1237259]
loss: 0.013906 [1230848/1237259]
Epoch 164
-------------------------------
loss: 0.013552 [ 2048/1237259]
loss: 0.015063 [206848/1237259]
loss: 0.014054 [411648/1237259]
loss: 0.016533 [616448/1237259]
loss: 0.014293 [821248/1237259]
loss: 0.014393 [1026048/1237259]
loss: 0.015514 [1230848/1237259]
Epoch 165
-------------------------------
loss: 0.012025 [ 2048/1237259]
loss: 0.012259 [206848/1237259]
loss: 0.012801 [411648/1237259]
loss: 0.014474 [616448/1237259]
loss: 0.015919 [821248/1237259]
loss: 0.014794 [1026048/1237259]
loss: 0.015993 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0564  
ndcg@20: 0.0456  
diversity: 0.1794  


Epoch 166
-------------------------------
loss: 0.014670 [ 2048/1237259]
loss: 0.015476 [206848/1237259]
loss: 0.013097 [411648/1237259]
loss: 0.012576 [616448/1237259]
loss: 0.014246 [821248/1237259]
loss: 0.014092 [1026048/1237259]
loss: 0.013343 [1230848/1237259]
Epoch 167
-------------------------------
loss: 0.015402 [ 2048/1237259]
loss: 0.013252 [206848/1237259]
loss: 0.012753 [411648/1237259]
loss: 0.014786 [616448/1237259]
loss: 0.013210 [821248/1237259]
loss: 0.014347 [1026048/1237259]
loss: 0.015588 [1230848/1237259]
Epoch 168
-------------------------------
loss: 0.014803 [ 2048/1237259]
loss: 0.012486 [206848/1237259]
loss: 0.013343 [411648/1237259]
loss: 0.016599 [616448/1237259]
loss: 0.014894 [821248/1237259]
loss: 0.013542 [1026048/1237259]
loss: 0.014063 [1230848/1237259]
Epoch 169
-------------------------------
loss: 0.012559 [ 2048/1237259]
loss: 0.013254 [206848/1237259]
loss: 0.015326 [411648/1237259]
loss: 0.012810 [616448/1237259]
loss: 0.013984 [821248/1237259]
loss: 0.013732 [1026048/1237259]
loss: 0.014711 [1230848/1237259]
Epoch 170
-------------------------------
loss: 0.014380 [ 2048/1237259]
loss: 0.013907 [206848/1237259]
loss: 0.014423 [411648/1237259]
loss: 0.014751 [616448/1237259]
loss: 0.012633 [821248/1237259]
loss: 0.015420 [1026048/1237259]
loss: 0.011966 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0564  
ndcg@20: 0.0456  
diversity: 0.1795  


Epoch 171
-------------------------------
loss: 0.014043 [ 2048/1237259]
loss: 0.014865 [206848/1237259]
loss: 0.015491 [411648/1237259]
loss: 0.011843 [616448/1237259]
loss: 0.013807 [821248/1237259]
loss: 0.014809 [1026048/1237259]
loss: 0.014369 [1230848/1237259]
Epoch 172
-------------------------------
loss: 0.013811 [ 2048/1237259]
loss: 0.013840 [206848/1237259]
loss: 0.014793 [411648/1237259]
loss: 0.014295 [616448/1237259]
loss: 0.014988 [821248/1237259]
loss: 0.013219 [1026048/1237259]
loss: 0.013337 [1230848/1237259]
Epoch 173
-------------------------------
loss: 0.012918 [ 2048/1237259]
loss: 0.014845 [206848/1237259]
loss: 0.014135 [411648/1237259]
loss: 0.014192 [616448/1237259]
loss: 0.013758 [821248/1237259]
loss: 0.012758 [1026048/1237259]
loss: 0.013347 [1230848/1237259]
Epoch 174
-------------------------------
loss: 0.012947 [ 2048/1237259]
loss: 0.012259 [206848/1237259]
loss: 0.014931 [411648/1237259]
loss: 0.013475 [616448/1237259]
loss: 0.015099 [821248/1237259]
loss: 0.013900 [1026048/1237259]
loss: 0.014934 [1230848/1237259]
Epoch 175
-------------------------------
loss: 0.013448 [ 2048/1237259]
loss: 0.016665 [206848/1237259]
loss: 0.014504 [411648/1237259]
loss: 0.016430 [616448/1237259]
loss: 0.014937 [821248/1237259]
loss: 0.012650 [1026048/1237259]
loss: 0.014235 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0570  
ndcg@20: 0.0459  
diversity: 0.1795  


Epoch 176
-------------------------------
loss: 0.013198 [ 2048/1237259]
loss: 0.014887 [206848/1237259]
loss: 0.013075 [411648/1237259]
loss: 0.013129 [616448/1237259]
loss: 0.014553 [821248/1237259]
loss: 0.014662 [1026048/1237259]
loss: 0.014538 [1230848/1237259]
Epoch 177
-------------------------------
loss: 0.012241 [ 2048/1237259]
loss: 0.013691 [206848/1237259]
loss: 0.013141 [411648/1237259]
loss: 0.012861 [616448/1237259]
loss: 0.013456 [821248/1237259]
loss: 0.015306 [1026048/1237259]
loss: 0.013121 [1230848/1237259]
Epoch 178
-------------------------------
loss: 0.014049 [ 2048/1237259]
loss: 0.012992 [206848/1237259]
loss: 0.012955 [411648/1237259]
loss: 0.015489 [616448/1237259]
loss: 0.014783 [821248/1237259]
loss: 0.014105 [1026048/1237259]
loss: 0.014463 [1230848/1237259]
Epoch 179
-------------------------------
loss: 0.014776 [ 2048/1237259]
loss: 0.014858 [206848/1237259]
loss: 0.012765 [411648/1237259]
loss: 0.014627 [616448/1237259]
loss: 0.014956 [821248/1237259]
loss: 0.014000 [1026048/1237259]
loss: 0.015941 [1230848/1237259]
Epoch 180
-------------------------------
loss: 0.014387 [ 2048/1237259]
loss: 0.012565 [206848/1237259]
loss: 0.014616 [411648/1237259]
loss: 0.015974 [616448/1237259]
loss: 0.014799 [821248/1237259]
loss: 0.015897 [1026048/1237259]
loss: 0.013587 [1230848/1237259]
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0569  
ndcg@20: 0.0460  
diversity: 0.1797  


Epoch 181
-------------------------------
loss: 0.013076 [ 2048/1237259]
loss: 0.015710 [206848/1237259]
loss: 0.013429 [411648/1237259]
loss: 0.014167 [616448/1237259]
loss: 0.014170 [821248/1237259]
loss: 0.014098 [1026048/1237259]
loss: 0.013060 [1230848/1237259]
Epoch 182
-------------------------------
loss: 0.012993 [ 2048/1237259]
loss: 0.013477 [206848/1237259]
loss: 0.013868 [411648/1237259]
loss: 0.013645 [616448/1237259]
loss: 0.015166 [821248/1237259]
loss: 0.014378 [1026048/1237259]
loss: 0.013724 [1230848/1237259]
Epoch 183
-------------------------------
loss: 0.015258 [ 2048/1237259]
loss: 0.014913 [206848/1237259]
loss: 0.017291 [411648/1237259]
loss: 0.012114 [616448/1237259]
loss: 0.014411 [821248/1237259]
loss: 0.015005 [1026048/1237259]
loss: 0.013417 [1230848/1237259]
Epoch 184
-------------------------------
loss: 0.014468 [ 2048/1237259]
loss: 0.013495 [206848/1237259]
loss: 0.014687 [411648/1237259]
loss: 0.012273 [616448/1237259]
loss: 0.015192 [821248/1237259]
loss: 0.013805 [1026048/1237259]
loss: 0.016428 [1230848/1237259]
Epoch 185
-------------------------------
loss: 0.013561 [ 2048/1237259]
loss: 0.012768 [206848/1237259]
loss: 0.014211 [411648/1237259]
loss: 0.013288 [616448/1237259]
loss: 0.014733 [821248/1237259]
loss: 0.013465 [1026048/1237259]
loss: 0.013864 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0571  
ndcg@20: 0.0462  
diversity: 0.1799  


Epoch 186
-------------------------------
loss: 0.013256 [ 2048/1237259]
loss: 0.014761 [206848/1237259]
loss: 0.014121 [411648/1237259]
loss: 0.014503 [616448/1237259]
loss: 0.013173 [821248/1237259]
loss: 0.015293 [1026048/1237259]
loss: 0.013649 [1230848/1237259]
Epoch 187
-------------------------------
loss: 0.015373 [ 2048/1237259]
loss: 0.013492 [206848/1237259]
loss: 0.012500 [411648/1237259]
loss: 0.014652 [616448/1237259]
loss: 0.013756 [821248/1237259]
loss: 0.013226 [1026048/1237259]
loss: 0.013917 [1230848/1237259]
Epoch 188
-------------------------------
loss: 0.014099 [ 2048/1237259]
loss: 0.014100 [206848/1237259]
loss: 0.014890 [411648/1237259]
loss: 0.013573 [616448/1237259]
loss: 0.014319 [821248/1237259]
loss: 0.013758 [1026048/1237259]
loss: 0.014307 [1230848/1237259]
Epoch 189
-------------------------------
loss: 0.012720 [ 2048/1237259]
loss: 0.012354 [206848/1237259]
loss: 0.014041 [411648/1237259]
loss: 0.012192 [616448/1237259]
loss: 0.011542 [821248/1237259]
loss: 0.013099 [1026048/1237259]
loss: 0.013017 [1230848/1237259]
Epoch 190
-------------------------------
loss: 0.016918 [ 2048/1237259]
loss: 0.015114 [206848/1237259]
loss: 0.015394 [411648/1237259]
loss: 0.013663 [616448/1237259]
loss: 0.014318 [821248/1237259]
loss: 0.015202 [1026048/1237259]
loss: 0.012842 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0573  
ndcg@20: 0.0464  
diversity: 0.1802  


Epoch 191
-------------------------------
loss: 0.013188 [ 2048/1237259]
loss: 0.015119 [206848/1237259]
loss: 0.012947 [411648/1237259]
loss: 0.013997 [616448/1237259]
loss: 0.013133 [821248/1237259]
loss: 0.014339 [1026048/1237259]
loss: 0.013132 [1230848/1237259]
Epoch 192
-------------------------------
loss: 0.013603 [ 2048/1237259]
loss: 0.013585 [206848/1237259]
loss: 0.013291 [411648/1237259]
loss: 0.015428 [616448/1237259]
loss: 0.013374 [821248/1237259]
loss: 0.013781 [1026048/1237259]
loss: 0.015550 [1230848/1237259]
Epoch 193
-------------------------------
loss: 0.014951 [ 2048/1237259]
loss: 0.014253 [206848/1237259]
loss: 0.013849 [411648/1237259]
loss: 0.014351 [616448/1237259]
loss: 0.013889 [821248/1237259]
loss: 0.012619 [1026048/1237259]
loss: 0.012754 [1230848/1237259]
Epoch 194
-------------------------------
loss: 0.014025 [ 2048/1237259]
loss: 0.013118 [206848/1237259]
loss: 0.013783 [411648/1237259]
loss: 0.014525 [616448/1237259]
loss: 0.013190 [821248/1237259]
loss: 0.014966 [1026048/1237259]
loss: 0.014507 [1230848/1237259]
Epoch 195
-------------------------------
loss: 0.014459 [ 2048/1237259]
loss: 0.013112 [206848/1237259]
loss: 0.013789 [411648/1237259]
loss: 0.014286 [616448/1237259]
loss: 0.012493 [821248/1237259]
loss: 0.012783 [1026048/1237259]
loss: 0.013292 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0576  
ndcg@20: 0.0466  
diversity: 0.1803  


Epoch 196
-------------------------------
loss: 0.012103 [ 2048/1237259]
loss: 0.015713 [206848/1237259]
loss: 0.015274 [411648/1237259]
loss: 0.014250 [616448/1237259]
loss: 0.015947 [821248/1237259]
loss: 0.014358 [1026048/1237259]
loss: 0.014030 [1230848/1237259]
Epoch 197
-------------------------------
loss: 0.014548 [ 2048/1237259]
loss: 0.014177 [206848/1237259]
loss: 0.013109 [411648/1237259]
loss: 0.013941 [616448/1237259]
loss: 0.012519 [821248/1237259]
loss: 0.014715 [1026048/1237259]
loss: 0.012442 [1230848/1237259]
Epoch 198
-------------------------------
loss: 0.016534 [ 2048/1237259]
loss: 0.016294 [206848/1237259]
loss: 0.014950 [411648/1237259]
loss: 0.013832 [616448/1237259]
loss: 0.012953 [821248/1237259]
loss: 0.016759 [1026048/1237259]
loss: 0.013343 [1230848/1237259]
Epoch 199
-------------------------------
loss: 0.014087 [ 2048/1237259]
loss: 0.017682 [206848/1237259]
loss: 0.014385 [411648/1237259]
loss: 0.015238 [616448/1237259]
loss: 0.013410 [821248/1237259]
loss: 0.013834 [1026048/1237259]
loss: 0.013510 [1230848/1237259]
Epoch 200
-------------------------------
loss: 0.014041 [ 2048/1237259]
loss: 0.014948 [206848/1237259]
loss: 0.014322 [411648/1237259]
loss: 0.013183 [616448/1237259]
loss: 0.012790 [821248/1237259]
loss: 0.012124 [1026048/1237259]
loss: 0.015100 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0579  
ndcg@20: 0.0468  
diversity: 0.1804  


Epoch 201
-------------------------------
loss: 0.013256 [ 2048/1237259]
loss: 0.012421 [206848/1237259]
loss: 0.013087 [411648/1237259]
loss: 0.011656 [616448/1237259]
loss: 0.014017 [821248/1237259]
loss: 0.015152 [1026048/1237259]
loss: 0.013809 [1230848/1237259]
Epoch 202
-------------------------------
loss: 0.011784 [ 2048/1237259]
loss: 0.015674 [206848/1237259]
loss: 0.013149 [411648/1237259]
loss: 0.015611 [616448/1237259]
loss: 0.012643 [821248/1237259]
loss: 0.012348 [1026048/1237259]
loss: 0.015266 [1230848/1237259]
Epoch 203
-------------------------------
loss: 0.013782 [ 2048/1237259]
loss: 0.014095 [206848/1237259]
loss: 0.014379 [411648/1237259]
loss: 0.013758 [616448/1237259]
loss: 0.014437 [821248/1237259]
loss: 0.014559 [1026048/1237259]
loss: 0.014456 [1230848/1237259]
Epoch 204
-------------------------------
loss: 0.013332 [ 2048/1237259]
loss: 0.014457 [206848/1237259]
loss: 0.014533 [411648/1237259]
loss: 0.014903 [616448/1237259]
loss: 0.014873 [821248/1237259]
loss: 0.013595 [1026048/1237259]
loss: 0.016024 [1230848/1237259]
Epoch 205
-------------------------------
loss: 0.012969 [ 2048/1237259]
loss: 0.012485 [206848/1237259]
loss: 0.014670 [411648/1237259]
loss: 0.014576 [616448/1237259]
loss: 0.015001 [821248/1237259]
loss: 0.014827 [1026048/1237259]
loss: 0.013162 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0581  
ndcg@20: 0.0469  
diversity: 0.1805  


Epoch 206
-------------------------------
loss: 0.012647 [ 2048/1237259]
loss: 0.015225 [206848/1237259]
loss: 0.015452 [411648/1237259]
loss: 0.014263 [616448/1237259]
loss: 0.014382 [821248/1237259]
loss: 0.012035 [1026048/1237259]
loss: 0.014783 [1230848/1237259]
Epoch 207
-------------------------------
loss: 0.016270 [ 2048/1237259]
loss: 0.012305 [206848/1237259]
loss: 0.014361 [411648/1237259]
loss: 0.014708 [616448/1237259]
loss: 0.012497 [821248/1237259]
loss: 0.013437 [1026048/1237259]
loss: 0.015237 [1230848/1237259]
Epoch 208
-------------------------------
loss: 0.014456 [ 2048/1237259]
loss: 0.014599 [206848/1237259]
loss: 0.014144 [411648/1237259]
loss: 0.014654 [616448/1237259]
loss: 0.012763 [821248/1237259]
loss: 0.014133 [1026048/1237259]
loss: 0.012600 [1230848/1237259]
Epoch 209
-------------------------------
loss: 0.013781 [ 2048/1237259]
loss: 0.013879 [206848/1237259]
loss: 0.014346 [411648/1237259]
loss: 0.012230 [616448/1237259]
loss: 0.013778 [821248/1237259]
loss: 0.013803 [1026048/1237259]
loss: 0.014055 [1230848/1237259]
Epoch 210
-------------------------------
loss: 0.014255 [ 2048/1237259]
loss: 0.013262 [206848/1237259]
loss: 0.012799 [411648/1237259]
loss: 0.014035 [616448/1237259]
loss: 0.012563 [821248/1237259]
loss: 0.012615 [1026048/1237259]
loss: 0.013986 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0583  
ndcg@20: 0.0471  
diversity: 0.1806  


Epoch 211
-------------------------------
loss: 0.012986 [ 2048/1237259]
loss: 0.016703 [206848/1237259]
loss: 0.015415 [411648/1237259]
loss: 0.014281 [616448/1237259]
loss: 0.013195 [821248/1237259]
loss: 0.015019 [1026048/1237259]
loss: 0.014728 [1230848/1237259]
Epoch 212
-------------------------------
loss: 0.013266 [ 2048/1237259]
loss: 0.013612 [206848/1237259]
loss: 0.013511 [411648/1237259]
loss: 0.015741 [616448/1237259]
loss: 0.013151 [821248/1237259]
loss: 0.013548 [1026048/1237259]
loss: 0.013233 [1230848/1237259]
Epoch 213
-------------------------------
loss: 0.014047 [ 2048/1237259]
loss: 0.013153 [206848/1237259]
loss: 0.012974 [411648/1237259]
loss: 0.012041 [616448/1237259]
loss: 0.014567 [821248/1237259]
loss: 0.012338 [1026048/1237259]
loss: 0.014907 [1230848/1237259]
Epoch 214
-------------------------------
loss: 0.014669 [ 2048/1237259]
loss: 0.013684 [206848/1237259]
loss: 0.014360 [411648/1237259]
loss: 0.013934 [616448/1237259]
loss: 0.014193 [821248/1237259]
loss: 0.013492 [1026048/1237259]
loss: 0.012583 [1230848/1237259]
Epoch 215
-------------------------------
loss: 0.015101 [ 2048/1237259]
loss: 0.014143 [206848/1237259]
loss: 0.014304 [411648/1237259]
loss: 0.013993 [616448/1237259]
loss: 0.012715 [821248/1237259]
loss: 0.013367 [1026048/1237259]
loss: 0.013783 [1230848/1237259]
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0583  
ndcg@20: 0.0470  
diversity: 0.1806  


Epoch 216
-------------------------------
loss: 0.013783 [ 2048/1237259]
loss: 0.013588 [206848/1237259]
loss: 0.012101 [411648/1237259]
loss: 0.012463 [616448/1237259]
loss: 0.013236 [821248/1237259]
loss: 0.013751 [1026048/1237259]
loss: 0.015085 [1230848/1237259]
Epoch 217
-------------------------------
loss: 0.012177 [ 2048/1237259]
loss: 0.012682 [206848/1237259]
loss: 0.014616 [411648/1237259]
loss: 0.013441 [616448/1237259]
loss: 0.014505 [821248/1237259]
loss: 0.013342 [1026048/1237259]
loss: 0.013608 [1230848/1237259]
Epoch 218
-------------------------------
loss: 0.013614 [ 2048/1237259]
loss: 0.014016 [206848/1237259]
loss: 0.013021 [411648/1237259]
loss: 0.013224 [616448/1237259]
loss: 0.014555 [821248/1237259]
loss: 0.013995 [1026048/1237259]
loss: 0.013456 [1230848/1237259]
Epoch 219
-------------------------------
loss: 0.014029 [ 2048/1237259]
loss: 0.014749 [206848/1237259]
loss: 0.013846 [411648/1237259]
loss: 0.012030 [616448/1237259]
loss: 0.014236 [821248/1237259]
loss: 0.015258 [1026048/1237259]
loss: 0.014970 [1230848/1237259]
Epoch 220
-------------------------------
loss: 0.014264 [ 2048/1237259]
loss: 0.011820 [206848/1237259]
loss: 0.013386 [411648/1237259]
loss: 0.013780 [616448/1237259]
loss: 0.014681 [821248/1237259]
loss: 0.013034 [1026048/1237259]
loss: 0.012719 [1230848/1237259]
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0582  
ndcg@20: 0.0470  
diversity: 0.1807  


Epoch 221
-------------------------------
loss: 0.013616 [ 2048/1237259]
loss: 0.014539 [206848/1237259]
loss: 0.013172 [411648/1237259]
loss: 0.016434 [616448/1237259]
loss: 0.012908 [821248/1237259]
loss: 0.015159 [1026048/1237259]
loss: 0.012318 [1230848/1237259]
Epoch 222
-------------------------------
loss: 0.013033 [ 2048/1237259]
loss: 0.014626 [206848/1237259]
loss: 0.016279 [411648/1237259]
loss: 0.012627 [616448/1237259]
loss: 0.015523 [821248/1237259]
loss: 0.015242 [1026048/1237259]
loss: 0.013112 [1230848/1237259]
Epoch 223
-------------------------------
loss: 0.014834 [ 2048/1237259]
loss: 0.014302 [206848/1237259]
loss: 0.012250 [411648/1237259]
loss: 0.013556 [616448/1237259]
loss: 0.015143 [821248/1237259]
loss: 0.013982 [1026048/1237259]
loss: 0.015265 [1230848/1237259]
Epoch 224
-------------------------------
loss: 0.015103 [ 2048/1237259]
loss: 0.014077 [206848/1237259]
loss: 0.014199 [411648/1237259]
loss: 0.013690 [616448/1237259]
loss: 0.014653 [821248/1237259]
loss: 0.013489 [1026048/1237259]
loss: 0.012286 [1230848/1237259]
Epoch 225
-------------------------------
loss: 0.013439 [ 2048/1237259]
loss: 0.013531 [206848/1237259]
loss: 0.013858 [411648/1237259]
loss: 0.014046 [616448/1237259]
loss: 0.014405 [821248/1237259]
loss: 0.013313 [1026048/1237259]
loss: 0.015138 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0586  
ndcg@20: 0.0472  
diversity: 0.1808  


Epoch 226
-------------------------------
loss: 0.011712 [ 2048/1237259]
loss: 0.013963 [206848/1237259]
loss: 0.013987 [411648/1237259]
loss: 0.014392 [616448/1237259]
loss: 0.013399 [821248/1237259]
loss: 0.013897 [1026048/1237259]
loss: 0.012354 [1230848/1237259]
Epoch 227
-------------------------------
loss: 0.013131 [ 2048/1237259]
loss: 0.014012 [206848/1237259]
loss: 0.012284 [411648/1237259]
loss: 0.015423 [616448/1237259]
loss: 0.012517 [821248/1237259]
loss: 0.013342 [1026048/1237259]
loss: 0.013488 [1230848/1237259]
Epoch 228
-------------------------------
loss: 0.015850 [ 2048/1237259]
loss: 0.014223 [206848/1237259]
loss: 0.013815 [411648/1237259]
loss: 0.012084 [616448/1237259]
loss: 0.013926 [821248/1237259]
loss: 0.012259 [1026048/1237259]
loss: 0.014034 [1230848/1237259]
Epoch 229
-------------------------------
loss: 0.013394 [ 2048/1237259]
loss: 0.014917 [206848/1237259]
loss: 0.012561 [411648/1237259]
loss: 0.012640 [616448/1237259]
loss: 0.014931 [821248/1237259]
loss: 0.014601 [1026048/1237259]
loss: 0.012966 [1230848/1237259]
Epoch 230
-------------------------------
loss: 0.013712 [ 2048/1237259]
loss: 0.013916 [206848/1237259]
loss: 0.013737 [411648/1237259]
loss: 0.014757 [616448/1237259]
loss: 0.016310 [821248/1237259]
loss: 0.014805 [1026048/1237259]
loss: 0.013837 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0588  
ndcg@20: 0.0474  
diversity: 0.1811  


Epoch 231
-------------------------------
loss: 0.013197 [ 2048/1237259]
loss: 0.014262 [206848/1237259]
loss: 0.013601 [411648/1237259]
loss: 0.014830 [616448/1237259]
loss: 0.013028 [821248/1237259]
loss: 0.013476 [1026048/1237259]
loss: 0.012414 [1230848/1237259]
Epoch 232
-------------------------------
loss: 0.012471 [ 2048/1237259]
loss: 0.013805 [206848/1237259]
loss: 0.013578 [411648/1237259]
loss: 0.013422 [616448/1237259]
loss: 0.010986 [821248/1237259]
loss: 0.013060 [1026048/1237259]
loss: 0.013813 [1230848/1237259]
Epoch 233
-------------------------------
loss: 0.013749 [ 2048/1237259]
loss: 0.013920 [206848/1237259]
loss: 0.014309 [411648/1237259]
loss: 0.015450 [616448/1237259]
loss: 0.013816 [821248/1237259]
loss: 0.012566 [1026048/1237259]
loss: 0.013411 [1230848/1237259]
Epoch 234
-------------------------------
loss: 0.014235 [ 2048/1237259]
loss: 0.013957 [206848/1237259]
loss: 0.013063 [411648/1237259]
loss: 0.013214 [616448/1237259]
loss: 0.014079 [821248/1237259]
loss: 0.011825 [1026048/1237259]
loss: 0.013199 [1230848/1237259]
Epoch 235
-------------------------------
loss: 0.014088 [ 2048/1237259]
loss: 0.013138 [206848/1237259]
loss: 0.012973 [411648/1237259]
loss: 0.012814 [616448/1237259]
loss: 0.013121 [821248/1237259]
loss: 0.014177 [1026048/1237259]
loss: 0.012326 [1230848/1237259]
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0586  
ndcg@20: 0.0473  
diversity: 0.1813  


Epoch 236
-------------------------------
loss: 0.012311 [ 2048/1237259]
loss: 0.015339 [206848/1237259]
loss: 0.012052 [411648/1237259]
loss: 0.013688 [616448/1237259]
loss: 0.014130 [821248/1237259]
loss: 0.014139 [1026048/1237259]
loss: 0.011303 [1230848/1237259]
Epoch 237
-------------------------------
loss: 0.012922 [ 2048/1237259]
loss: 0.015706 [206848/1237259]
loss: 0.016257 [411648/1237259]
loss: 0.013599 [616448/1237259]
loss: 0.014168 [821248/1237259]
loss: 0.014771 [1026048/1237259]
loss: 0.014518 [1230848/1237259]
Epoch 238
-------------------------------
loss: 0.012590 [ 2048/1237259]
loss: 0.013650 [206848/1237259]
loss: 0.012432 [411648/1237259]
loss: 0.014936 [616448/1237259]
loss: 0.012679 [821248/1237259]
loss: 0.013306 [1026048/1237259]
loss: 0.013567 [1230848/1237259]
Epoch 239
-------------------------------
loss: 0.014320 [ 2048/1237259]
loss: 0.013739 [206848/1237259]
loss: 0.012263 [411648/1237259]
loss: 0.012780 [616448/1237259]
loss: 0.012887 [821248/1237259]
loss: 0.012114 [1026048/1237259]
loss: 0.012241 [1230848/1237259]
Epoch 240
-------------------------------
loss: 0.014761 [ 2048/1237259]
loss: 0.012736 [206848/1237259]
loss: 0.012616 [411648/1237259]
loss: 0.013294 [616448/1237259]
loss: 0.013033 [821248/1237259]
loss: 0.012329 [1026048/1237259]
loss: 0.014121 [1230848/1237259]
Best ndcg@20 model updated. Saving the model.
Eval results: 
recall@20: 0.0587  
ndcg@20: 0.0474  
diversity: 0.1813  


Epoch 241
-------------------------------
loss: 0.013211 [ 2048/1237259]
loss: 0.014910 [206848/1237259]
loss: 0.014990 [411648/1237259]
loss: 0.014641 [616448/1237259]
loss: 0.013529 [821248/1237259]
loss: 0.014451 [1026048/1237259]
loss: 0.013692 [1230848/1237259]
Epoch 242
-------------------------------
loss: 0.016137 [ 2048/1237259]
loss: 0.012271 [206848/1237259]
loss: 0.016118 [411648/1237259]
loss: 0.014496 [616448/1237259]
loss: 0.013864 [821248/1237259]
loss: 0.013386 [1026048/1237259]
loss: 0.012798 [1230848/1237259]
Epoch 243
-------------------------------
loss: 0.013415 [ 2048/1237259]
loss: 0.012550 [206848/1237259]
loss: 0.014611 [411648/1237259]
loss: 0.014869 [616448/1237259]
loss: 0.012668 [821248/1237259]
loss: 0.011915 [1026048/1237259]
loss: 0.013356 [1230848/1237259]
Epoch 244
-------------------------------
loss: 0.015458 [ 2048/1237259]
loss: 0.014701 [206848/1237259]
loss: 0.013288 [411648/1237259]
loss: 0.013256 [616448/1237259]
loss: 0.014567 [821248/1237259]
loss: 0.012560 [1026048/1237259]
loss: 0.015254 [1230848/1237259]
Epoch 245
-------------------------------
loss: 0.013019 [ 2048/1237259]
loss: 0.012194 [206848/1237259]
loss: 0.013487 [411648/1237259]
loss: 0.013511 [616448/1237259]
loss: 0.011955 [821248/1237259]
loss: 0.012938 [1026048/1237259]
loss: 0.013879 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0589  
ndcg@20: 0.0475  
diversity: 0.1814  


Epoch 246
-------------------------------
loss: 0.014000 [ 2048/1237259]
loss: 0.012972 [206848/1237259]
loss: 0.013517 [411648/1237259]
loss: 0.014570 [616448/1237259]
loss: 0.013182 [821248/1237259]
loss: 0.013269 [1026048/1237259]
loss: 0.013513 [1230848/1237259]
Epoch 247
-------------------------------
loss: 0.012329 [ 2048/1237259]
loss: 0.013465 [206848/1237259]
loss: 0.012918 [411648/1237259]
loss: 0.016549 [616448/1237259]
loss: 0.014615 [821248/1237259]
loss: 0.013803 [1026048/1237259]
loss: 0.014287 [1230848/1237259]
Epoch 248
-------------------------------
loss: 0.012151 [ 2048/1237259]
loss: 0.012728 [206848/1237259]
loss: 0.013245 [411648/1237259]
loss: 0.013185 [616448/1237259]
loss: 0.012206 [821248/1237259]
loss: 0.013640 [1026048/1237259]
loss: 0.012723 [1230848/1237259]
Epoch 249
-------------------------------
loss: 0.014976 [ 2048/1237259]
loss: 0.013103 [206848/1237259]
loss: 0.013867 [411648/1237259]
loss: 0.013988 [616448/1237259]
loss: 0.013983 [821248/1237259]
loss: 0.012010 [1026048/1237259]
loss: 0.013258 [1230848/1237259]
Epoch 250
-------------------------------
loss: 0.013771 [ 2048/1237259]
loss: 0.012151 [206848/1237259]
loss: 0.013535 [411648/1237259]
loss: 0.013477 [616448/1237259]
loss: 0.014416 [821248/1237259]
loss: 0.012282 [1026048/1237259]
loss: 0.012007 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0590  
ndcg@20: 0.0475  
diversity: 0.1816  


Epoch 251
-------------------------------
loss: 0.013131 [ 2048/1237259]
loss: 0.014396 [206848/1237259]
loss: 0.013340 [411648/1237259]
loss: 0.014608 [616448/1237259]
loss: 0.013180 [821248/1237259]
loss: 0.013893 [1026048/1237259]
loss: 0.013253 [1230848/1237259]
Epoch 252
-------------------------------
loss: 0.011859 [ 2048/1237259]
loss: 0.015700 [206848/1237259]
loss: 0.012568 [411648/1237259]
loss: 0.013586 [616448/1237259]
loss: 0.014307 [821248/1237259]
loss: 0.014372 [1026048/1237259]
loss: 0.014479 [1230848/1237259]
Epoch 253
-------------------------------
loss: 0.016381 [ 2048/1237259]
loss: 0.014044 [206848/1237259]
loss: 0.011350 [411648/1237259]
loss: 0.015120 [616448/1237259]
loss: 0.014909 [821248/1237259]
loss: 0.011830 [1026048/1237259]
loss: 0.012938 [1230848/1237259]
Epoch 254
-------------------------------
loss: 0.013153 [ 2048/1237259]
loss: 0.014390 [206848/1237259]
loss: 0.014193 [411648/1237259]
loss: 0.016458 [616448/1237259]
loss: 0.012670 [821248/1237259]
loss: 0.015160 [1026048/1237259]
loss: 0.013292 [1230848/1237259]
Epoch 255
-------------------------------
loss: 0.012514 [ 2048/1237259]
loss: 0.013249 [206848/1237259]
loss: 0.013503 [411648/1237259]
loss: 0.011960 [616448/1237259]
loss: 0.014120 [821248/1237259]
loss: 0.012466 [1026048/1237259]
loss: 0.013440 [1230848/1237259]
Best ndcg@20 model updated. Saving the model.
Eval results: 
recall@20: 0.0590  
ndcg@20: 0.0476  
diversity: 0.1815  


Epoch 256
-------------------------------
loss: 0.014034 [ 2048/1237259]
loss: 0.014530 [206848/1237259]
loss: 0.015035 [411648/1237259]
loss: 0.014622 [616448/1237259]
loss: 0.015353 [821248/1237259]
loss: 0.013361 [1026048/1237259]
loss: 0.012926 [1230848/1237259]
Epoch 257
-------------------------------
loss: 0.013388 [ 2048/1237259]
loss: 0.012790 [206848/1237259]
loss: 0.015362 [411648/1237259]
loss: 0.013442 [616448/1237259]
loss: 0.012302 [821248/1237259]
loss: 0.013290 [1026048/1237259]
loss: 0.014304 [1230848/1237259]
Epoch 258
-------------------------------
loss: 0.014942 [ 2048/1237259]
loss: 0.012733 [206848/1237259]
loss: 0.013931 [411648/1237259]
loss: 0.013039 [616448/1237259]
loss: 0.015603 [821248/1237259]
loss: 0.012646 [1026048/1237259]
loss: 0.013285 [1230848/1237259]
Epoch 259
-------------------------------
loss: 0.014648 [ 2048/1237259]
loss: 0.012378 [206848/1237259]
loss: 0.014388 [411648/1237259]
loss: 0.013459 [616448/1237259]
loss: 0.014968 [821248/1237259]
loss: 0.013751 [1026048/1237259]
loss: 0.012990 [1230848/1237259]
Epoch 260
-------------------------------
loss: 0.012759 [ 2048/1237259]
loss: 0.013876 [206848/1237259]
loss: 0.012760 [411648/1237259]
loss: 0.012690 [616448/1237259]
loss: 0.013745 [821248/1237259]
loss: 0.014261 [1026048/1237259]
loss: 0.012354 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0593  
ndcg@20: 0.0478  
diversity: 0.1817  


Epoch 261
-------------------------------
loss: 0.012469 [ 2048/1237259]
loss: 0.015027 [206848/1237259]
loss: 0.012655 [411648/1237259]
loss: 0.011659 [616448/1237259]
loss: 0.014005 [821248/1237259]
loss: 0.012875 [1026048/1237259]
loss: 0.013597 [1230848/1237259]
Epoch 262
-------------------------------
loss: 0.013309 [ 2048/1237259]
loss: 0.012774 [206848/1237259]
loss: 0.011601 [411648/1237259]
loss: 0.013076 [616448/1237259]
loss: 0.013924 [821248/1237259]
loss: 0.012882 [1026048/1237259]
loss: 0.014842 [1230848/1237259]
Epoch 263
-------------------------------
loss: 0.014853 [ 2048/1237259]
loss: 0.012502 [206848/1237259]
loss: 0.014151 [411648/1237259]
loss: 0.014502 [616448/1237259]
loss: 0.013330 [821248/1237259]
loss: 0.013469 [1026048/1237259]
loss: 0.011733 [1230848/1237259]
Epoch 264
-------------------------------
loss: 0.012816 [ 2048/1237259]
loss: 0.015653 [206848/1237259]
loss: 0.012832 [411648/1237259]
loss: 0.012394 [616448/1237259]
loss: 0.012872 [821248/1237259]
loss: 0.012297 [1026048/1237259]
loss: 0.012832 [1230848/1237259]
Epoch 265
-------------------------------
loss: 0.013314 [ 2048/1237259]
loss: 0.013480 [206848/1237259]
loss: 0.013507 [411648/1237259]
loss: 0.012718 [616448/1237259]
loss: 0.013224 [821248/1237259]
loss: 0.014120 [1026048/1237259]
loss: 0.012021 [1230848/1237259]
Best ndcg@20 model updated. Saving the model.
Eval results: 
recall@20: 0.0593  
ndcg@20: 0.0479  
diversity: 0.1816  


Epoch 266
-------------------------------
loss: 0.012759 [ 2048/1237259]
loss: 0.014653 [206848/1237259]
loss: 0.012905 [411648/1237259]
loss: 0.013833 [616448/1237259]
loss: 0.014253 [821248/1237259]
loss: 0.012426 [1026048/1237259]
loss: 0.013612 [1230848/1237259]
Epoch 267
-------------------------------
loss: 0.012110 [ 2048/1237259]
loss: 0.013616 [206848/1237259]
loss: 0.013695 [411648/1237259]
loss: 0.012516 [616448/1237259]
loss: 0.012887 [821248/1237259]
loss: 0.014737 [1026048/1237259]
loss: 0.013021 [1230848/1237259]
Epoch 268
-------------------------------
loss: 0.012430 [ 2048/1237259]
loss: 0.014115 [206848/1237259]
loss: 0.014301 [411648/1237259]
loss: 0.015860 [616448/1237259]
loss: 0.013869 [821248/1237259]
loss: 0.012984 [1026048/1237259]
loss: 0.014342 [1230848/1237259]
Epoch 269
-------------------------------
loss: 0.012345 [ 2048/1237259]
loss: 0.011741 [206848/1237259]
loss: 0.015949 [411648/1237259]
loss: 0.013012 [616448/1237259]
loss: 0.012174 [821248/1237259]
loss: 0.013137 [1026048/1237259]
loss: 0.012907 [1230848/1237259]
Epoch 270
-------------------------------
loss: 0.012586 [ 2048/1237259]
loss: 0.012187 [206848/1237259]
loss: 0.013277 [411648/1237259]
loss: 0.012120 [616448/1237259]
loss: 0.011838 [821248/1237259]
loss: 0.013330 [1026048/1237259]
loss: 0.014531 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0594  
ndcg@20: 0.0480  
diversity: 0.1818  


Epoch 271
-------------------------------
loss: 0.013298 [ 2048/1237259]
loss: 0.012861 [206848/1237259]
loss: 0.012654 [411648/1237259]
loss: 0.012450 [616448/1237259]
loss: 0.013749 [821248/1237259]
loss: 0.013467 [1026048/1237259]
loss: 0.012470 [1230848/1237259]
Epoch 272
-------------------------------
loss: 0.013216 [ 2048/1237259]
loss: 0.012104 [206848/1237259]
loss: 0.014094 [411648/1237259]
loss: 0.012420 [616448/1237259]
loss: 0.016170 [821248/1237259]
loss: 0.013912 [1026048/1237259]
loss: 0.013158 [1230848/1237259]
Epoch 273
-------------------------------
loss: 0.013841 [ 2048/1237259]
loss: 0.014551 [206848/1237259]
loss: 0.014094 [411648/1237259]
loss: 0.012513 [616448/1237259]
loss: 0.012554 [821248/1237259]
loss: 0.014025 [1026048/1237259]
loss: 0.013264 [1230848/1237259]
Epoch 274
-------------------------------
loss: 0.014454 [ 2048/1237259]
loss: 0.012904 [206848/1237259]
loss: 0.014356 [411648/1237259]
loss: 0.014065 [616448/1237259]
loss: 0.013656 [821248/1237259]
loss: 0.012623 [1026048/1237259]
loss: 0.013491 [1230848/1237259]
Epoch 275
-------------------------------
loss: 0.013319 [ 2048/1237259]
loss: 0.014520 [206848/1237259]
loss: 0.012995 [411648/1237259]
loss: 0.011672 [616448/1237259]
loss: 0.012604 [821248/1237259]
loss: 0.012197 [1026048/1237259]
loss: 0.013511 [1230848/1237259]
Eval results: 
recall@20: 0.0592  
ndcg@20: 0.0479  
diversity: 0.1817  


Epoch 276
-------------------------------
loss: 0.014054 [ 2048/1237259]
loss: 0.013655 [206848/1237259]
loss: 0.011884 [411648/1237259]
loss: 0.013060 [616448/1237259]
loss: 0.013845 [821248/1237259]
loss: 0.012548 [1026048/1237259]
loss: 0.012185 [1230848/1237259]
Epoch 277
-------------------------------
loss: 0.014213 [ 2048/1237259]
loss: 0.012314 [206848/1237259]
loss: 0.011721 [411648/1237259]
loss: 0.013587 [616448/1237259]
loss: 0.014071 [821248/1237259]
loss: 0.014541 [1026048/1237259]
loss: 0.011617 [1230848/1237259]
Epoch 278
-------------------------------
loss: 0.013182 [ 2048/1237259]
loss: 0.014224 [206848/1237259]
loss: 0.013305 [411648/1237259]
loss: 0.012377 [616448/1237259]
loss: 0.013596 [821248/1237259]
loss: 0.014679 [1026048/1237259]
loss: 0.014067 [1230848/1237259]
Epoch 279
-------------------------------
loss: 0.011162 [ 2048/1237259]
loss: 0.013023 [206848/1237259]
loss: 0.012511 [411648/1237259]
loss: 0.014317 [616448/1237259]
loss: 0.011910 [821248/1237259]
loss: 0.013563 [1026048/1237259]
loss: 0.013912 [1230848/1237259]
Epoch 280
-------------------------------
loss: 0.012828 [ 2048/1237259]
loss: 0.012109 [206848/1237259]
loss: 0.015258 [411648/1237259]
loss: 0.015022 [616448/1237259]
loss: 0.013463 [821248/1237259]
loss: 0.013396 [1026048/1237259]
loss: 0.013825 [1230848/1237259]
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0593  
ndcg@20: 0.0480  
diversity: 0.1819  


Epoch 281
-------------------------------
loss: 0.012236 [ 2048/1237259]
loss: 0.012249 [206848/1237259]
loss: 0.012514 [411648/1237259]
loss: 0.013467 [616448/1237259]
loss: 0.013567 [821248/1237259]
loss: 0.013548 [1026048/1237259]
loss: 0.012577 [1230848/1237259]
Epoch 282
-------------------------------
loss: 0.014642 [ 2048/1237259]
loss: 0.012793 [206848/1237259]
loss: 0.013491 [411648/1237259]
loss: 0.013668 [616448/1237259]
loss: 0.013248 [821248/1237259]
loss: 0.012760 [1026048/1237259]
loss: 0.013221 [1230848/1237259]
Epoch 283
-------------------------------
loss: 0.013019 [ 2048/1237259]
loss: 0.013226 [206848/1237259]
loss: 0.014271 [411648/1237259]
loss: 0.013349 [616448/1237259]
loss: 0.011628 [821248/1237259]
loss: 0.012998 [1026048/1237259]
loss: 0.013283 [1230848/1237259]
Epoch 284
-------------------------------
loss: 0.014361 [ 2048/1237259]
loss: 0.012419 [206848/1237259]
loss: 0.015118 [411648/1237259]
loss: 0.012056 [616448/1237259]
loss: 0.012458 [821248/1237259]
loss: 0.012607 [1026048/1237259]
loss: 0.013584 [1230848/1237259]
Epoch 285
-------------------------------
loss: 0.012187 [ 2048/1237259]
loss: 0.012526 [206848/1237259]
loss: 0.012350 [411648/1237259]
loss: 0.012149 [616448/1237259]
loss: 0.014042 [821248/1237259]
loss: 0.013161 [1026048/1237259]
loss: 0.012206 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0597  
ndcg@20: 0.0482  
diversity: 0.1819  


Epoch 286
-------------------------------
loss: 0.013982 [ 2048/1237259]
loss: 0.013631 [206848/1237259]
loss: 0.013062 [411648/1237259]
loss: 0.013725 [616448/1237259]
loss: 0.014499 [821248/1237259]
loss: 0.013882 [1026048/1237259]
loss: 0.012460 [1230848/1237259]
Epoch 287
-------------------------------
loss: 0.013892 [ 2048/1237259]
loss: 0.013112 [206848/1237259]
loss: 0.012128 [411648/1237259]
loss: 0.014384 [616448/1237259]
loss: 0.011887 [821248/1237259]
loss: 0.014253 [1026048/1237259]
loss: 0.015076 [1230848/1237259]
Epoch 288
-------------------------------
loss: 0.012229 [ 2048/1237259]
loss: 0.012553 [206848/1237259]
loss: 0.012799 [411648/1237259]
loss: 0.012587 [616448/1237259]
loss: 0.013647 [821248/1237259]
loss: 0.013201 [1026048/1237259]
loss: 0.013319 [1230848/1237259]
Epoch 289
-------------------------------
loss: 0.013151 [ 2048/1237259]
loss: 0.013414 [206848/1237259]
loss: 0.013931 [411648/1237259]
loss: 0.011930 [616448/1237259]
loss: 0.012493 [821248/1237259]
loss: 0.013383 [1026048/1237259]
loss: 0.013702 [1230848/1237259]
Epoch 290
-------------------------------
loss: 0.011885 [ 2048/1237259]
loss: 0.012846 [206848/1237259]
loss: 0.012775 [411648/1237259]
loss: 0.014446 [616448/1237259]
loss: 0.013161 [821248/1237259]
loss: 0.013510 [1026048/1237259]
loss: 0.012808 [1230848/1237259]
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0595  
ndcg@20: 0.0481  
diversity: 0.1823  


Epoch 291
-------------------------------
loss: 0.012772 [ 2048/1237259]
loss: 0.012305 [206848/1237259]
loss: 0.013355 [411648/1237259]
loss: 0.013125 [616448/1237259]
loss: 0.012519 [821248/1237259]
loss: 0.013823 [1026048/1237259]
loss: 0.014555 [1230848/1237259]
Epoch 292
-------------------------------
loss: 0.011273 [ 2048/1237259]
loss: 0.013251 [206848/1237259]
loss: 0.012250 [411648/1237259]
loss: 0.012858 [616448/1237259]
loss: 0.013501 [821248/1237259]
loss: 0.012131 [1026048/1237259]
loss: 0.014038 [1230848/1237259]
Epoch 293
-------------------------------
loss: 0.013988 [ 2048/1237259]
loss: 0.013686 [206848/1237259]
loss: 0.011867 [411648/1237259]
loss: 0.012762 [616448/1237259]
loss: 0.012020 [821248/1237259]
loss: 0.012118 [1026048/1237259]
loss: 0.013983 [1230848/1237259]
Epoch 294
-------------------------------
loss: 0.013651 [ 2048/1237259]
loss: 0.011732 [206848/1237259]
loss: 0.013670 [411648/1237259]
loss: 0.012840 [616448/1237259]
loss: 0.014239 [821248/1237259]
loss: 0.013470 [1026048/1237259]
loss: 0.015772 [1230848/1237259]
Epoch 295
-------------------------------
loss: 0.011523 [ 2048/1237259]
loss: 0.013704 [206848/1237259]
loss: 0.013866 [411648/1237259]
loss: 0.013056 [616448/1237259]
loss: 0.013662 [821248/1237259]
loss: 0.011351 [1026048/1237259]
loss: 0.011958 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Eval results: 
recall@20: 0.0601  
ndcg@20: 0.0485  
diversity: 0.1821  


Epoch 296
-------------------------------
loss: 0.015023 [ 2048/1237259]
loss: 0.013471 [206848/1237259]
loss: 0.013784 [411648/1237259]
loss: 0.012379 [616448/1237259]
loss: 0.014275 [821248/1237259]
loss: 0.012140 [1026048/1237259]
loss: 0.013006 [1230848/1237259]
Epoch 297
-------------------------------
loss: 0.012917 [ 2048/1237259]
loss: 0.014428 [206848/1237259]
loss: 0.014601 [411648/1237259]
loss: 0.012783 [616448/1237259]
loss: 0.012766 [821248/1237259]
loss: 0.014020 [1026048/1237259]
loss: 0.013281 [1230848/1237259]
Epoch 298
-------------------------------
loss: 0.012680 [ 2048/1237259]
loss: 0.014526 [206848/1237259]
loss: 0.011636 [411648/1237259]
loss: 0.012724 [616448/1237259]
loss: 0.014258 [821248/1237259]
loss: 0.013228 [1026048/1237259]
loss: 0.012463 [1230848/1237259]
Epoch 299
-------------------------------
loss: 0.012765 [ 2048/1237259]
loss: 0.011785 [206848/1237259]
loss: 0.012097 [411648/1237259]
loss: 0.013100 [616448/1237259]
loss: 0.011669 [821248/1237259]
loss: 0.012246 [1026048/1237259]
loss: 0.014364 [1230848/1237259]
Epoch 300
-------------------------------
loss: 0.012453 [ 2048/1237259]
loss: 0.015713 [206848/1237259]
loss: 0.013684 [411648/1237259]
loss: 0.011947 [616448/1237259]
loss: 0.013452 [821248/1237259]
loss: 0.013080 [1026048/1237259]
loss: 0.013836 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0601  
ndcg@20: 0.0485  
diversity: 0.1823  


Epoch 301
-------------------------------
loss: 0.014876 [ 2048/1237259]
loss: 0.012125 [206848/1237259]
loss: 0.013297 [411648/1237259]
loss: 0.014668 [616448/1237259]
loss: 0.012363 [821248/1237259]
loss: 0.012023 [1026048/1237259]
loss: 0.011990 [1230848/1237259]
Epoch 302
-------------------------------
loss: 0.014119 [ 2048/1237259]
loss: 0.013330 [206848/1237259]
loss: 0.012045 [411648/1237259]
loss: 0.013054 [616448/1237259]
loss: 0.014026 [821248/1237259]
loss: 0.014055 [1026048/1237259]
loss: 0.013257 [1230848/1237259]
Epoch 303
-------------------------------
loss: 0.016324 [ 2048/1237259]
loss: 0.012690 [206848/1237259]
loss: 0.013161 [411648/1237259]
loss: 0.014531 [616448/1237259]
loss: 0.014095 [821248/1237259]
loss: 0.013087 [1026048/1237259]
loss: 0.013325 [1230848/1237259]
Epoch 304
-------------------------------
loss: 0.011706 [ 2048/1237259]
loss: 0.013188 [206848/1237259]
loss: 0.013326 [411648/1237259]
loss: 0.012428 [616448/1237259]
loss: 0.013900 [821248/1237259]
loss: 0.012612 [1026048/1237259]
loss: 0.013745 [1230848/1237259]
Epoch 305
-------------------------------
loss: 0.014595 [ 2048/1237259]
loss: 0.012980 [206848/1237259]
loss: 0.011862 [411648/1237259]
loss: 0.011609 [616448/1237259]
loss: 0.014130 [821248/1237259]
loss: 0.014577 [1026048/1237259]
loss: 0.012947 [1230848/1237259]
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0601  
ndcg@20: 0.0484  
diversity: 0.1824  


Epoch 306
-------------------------------
loss: 0.013259 [ 2048/1237259]
loss: 0.014208 [206848/1237259]
loss: 0.014311 [411648/1237259]
loss: 0.012035 [616448/1237259]
loss: 0.013335 [821248/1237259]
loss: 0.012427 [1026048/1237259]
loss: 0.012652 [1230848/1237259]
Epoch 307
-------------------------------
loss: 0.014902 [ 2048/1237259]
loss: 0.013161 [206848/1237259]
loss: 0.015364 [411648/1237259]
loss: 0.014071 [616448/1237259]
loss: 0.013994 [821248/1237259]
loss: 0.015607 [1026048/1237259]
loss: 0.013916 [1230848/1237259]
Epoch 308
-------------------------------
loss: 0.013374 [ 2048/1237259]
loss: 0.013651 [206848/1237259]
loss: 0.013805 [411648/1237259]
loss: 0.013750 [616448/1237259]
loss: 0.012106 [821248/1237259]
loss: 0.013876 [1026048/1237259]
loss: 0.011835 [1230848/1237259]
Epoch 309
-------------------------------
loss: 0.013160 [ 2048/1237259]
loss: 0.012846 [206848/1237259]
loss: 0.016019 [411648/1237259]
loss: 0.013962 [616448/1237259]
loss: 0.016030 [821248/1237259]
loss: 0.013539 [1026048/1237259]
loss: 0.013660 [1230848/1237259]
Epoch 310
-------------------------------
loss: 0.012591 [ 2048/1237259]
loss: 0.015017 [206848/1237259]
loss: 0.013521 [411648/1237259]
loss: 0.011718 [616448/1237259]
loss: 0.013594 [821248/1237259]
loss: 0.012740 [1026048/1237259]
loss: 0.013399 [1230848/1237259]
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0599  
ndcg@20: 0.0483  
diversity: 0.1824  


Epoch 311
-------------------------------
loss: 0.012159 [ 2048/1237259]
loss: 0.012753 [206848/1237259]
loss: 0.012428 [411648/1237259]
loss: 0.012365 [616448/1237259]
loss: 0.012701 [821248/1237259]
loss: 0.013221 [1026048/1237259]
loss: 0.012882 [1230848/1237259]
Epoch 312
-------------------------------
loss: 0.012831 [ 2048/1237259]
loss: 0.013760 [206848/1237259]
loss: 0.011996 [411648/1237259]
loss: 0.012912 [616448/1237259]
loss: 0.013183 [821248/1237259]
loss: 0.012855 [1026048/1237259]
loss: 0.013191 [1230848/1237259]
Epoch 313
-------------------------------
loss: 0.012721 [ 2048/1237259]
loss: 0.012853 [206848/1237259]
loss: 0.012454 [411648/1237259]
loss: 0.013336 [616448/1237259]
loss: 0.012018 [821248/1237259]
loss: 0.013801 [1026048/1237259]
loss: 0.014069 [1230848/1237259]
Epoch 314
-------------------------------
loss: 0.013022 [ 2048/1237259]
loss: 0.013636 [206848/1237259]
loss: 0.013828 [411648/1237259]
loss: 0.013064 [616448/1237259]
loss: 0.012433 [821248/1237259]
loss: 0.012979 [1026048/1237259]
loss: 0.013417 [1230848/1237259]
Epoch 315
-------------------------------
loss: 0.013533 [ 2048/1237259]
loss: 0.013202 [206848/1237259]
loss: 0.014212 [411648/1237259]
loss: 0.012683 [616448/1237259]
loss: 0.013488 [821248/1237259]
loss: 0.012286 [1026048/1237259]
loss: 0.012908 [1230848/1237259]
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0601  
ndcg@20: 0.0484  
diversity: 0.1825  


Epoch 316
-------------------------------
loss: 0.012754 [ 2048/1237259]
loss: 0.013080 [206848/1237259]
loss: 0.013380 [411648/1237259]
loss: 0.011900 [616448/1237259]
loss: 0.013428 [821248/1237259]
loss: 0.014924 [1026048/1237259]
loss: 0.014647 [1230848/1237259]
Epoch 317
-------------------------------
loss: 0.012902 [ 2048/1237259]
loss: 0.013409 [206848/1237259]
loss: 0.013802 [411648/1237259]
loss: 0.012888 [616448/1237259]
loss: 0.015018 [821248/1237259]
loss: 0.012100 [1026048/1237259]
loss: 0.014168 [1230848/1237259]
Epoch 318
-------------------------------
loss: 0.011767 [ 2048/1237259]
loss: 0.016496 [206848/1237259]
loss: 0.015532 [411648/1237259]
loss: 0.011684 [616448/1237259]
loss: 0.012541 [821248/1237259]
loss: 0.011589 [1026048/1237259]
loss: 0.013173 [1230848/1237259]
Epoch 319
-------------------------------
loss: 0.012133 [ 2048/1237259]
loss: 0.012296 [206848/1237259]
loss: 0.013445 [411648/1237259]
loss: 0.013122 [616448/1237259]
loss: 0.013223 [821248/1237259]
loss: 0.013281 [1026048/1237259]
loss: 0.012205 [1230848/1237259]
Epoch 320
-------------------------------
loss: 0.012534 [ 2048/1237259]
loss: 0.014191 [206848/1237259]
loss: 0.012709 [411648/1237259]
loss: 0.015110 [616448/1237259]
loss: 0.011475 [821248/1237259]
loss: 0.012212 [1026048/1237259]
loss: 0.013251 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Eval results: 
recall@20: 0.0603  
ndcg@20: 0.0487  
diversity: 0.1825  


Epoch 321
-------------------------------
loss: 0.013211 [ 2048/1237259]
loss: 0.012620 [206848/1237259]
loss: 0.013234 [411648/1237259]
loss: 0.012851 [616448/1237259]
loss: 0.014194 [821248/1237259]
loss: 0.012780 [1026048/1237259]
loss: 0.013844 [1230848/1237259]
Epoch 322
-------------------------------
loss: 0.013508 [ 2048/1237259]
loss: 0.012040 [206848/1237259]
loss: 0.013884 [411648/1237259]
loss: 0.012326 [616448/1237259]
loss: 0.014945 [821248/1237259]
loss: 0.013758 [1026048/1237259]
loss: 0.013770 [1230848/1237259]
Epoch 323
-------------------------------
loss: 0.014868 [ 2048/1237259]
loss: 0.012505 [206848/1237259]
loss: 0.012848 [411648/1237259]
loss: 0.013989 [616448/1237259]
loss: 0.012216 [821248/1237259]
loss: 0.012998 [1026048/1237259]
loss: 0.012429 [1230848/1237259]
Epoch 324
-------------------------------
loss: 0.012301 [ 2048/1237259]
loss: 0.013151 [206848/1237259]
loss: 0.013401 [411648/1237259]
loss: 0.013403 [616448/1237259]
loss: 0.012175 [821248/1237259]
loss: 0.014406 [1026048/1237259]
loss: 0.012916 [1230848/1237259]
Epoch 325
-------------------------------
loss: 0.012550 [ 2048/1237259]
loss: 0.012397 [206848/1237259]
loss: 0.013511 [411648/1237259]
loss: 0.013455 [616448/1237259]
loss: 0.012915 [821248/1237259]
loss: 0.013406 [1026048/1237259]
loss: 0.011587 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0604  
ndcg@20: 0.0486  
diversity: 0.1826  


Epoch 326
-------------------------------
loss: 0.012388 [ 2048/1237259]
loss: 0.011261 [206848/1237259]
loss: 0.014675 [411648/1237259]
loss: 0.012463 [616448/1237259]
loss: 0.013278 [821248/1237259]
loss: 0.014541 [1026048/1237259]
loss: 0.012833 [1230848/1237259]
Epoch 327
-------------------------------
loss: 0.014331 [ 2048/1237259]
loss: 0.012102 [206848/1237259]
loss: 0.012393 [411648/1237259]
loss: 0.013374 [616448/1237259]
loss: 0.013649 [821248/1237259]
loss: 0.013155 [1026048/1237259]
loss: 0.012520 [1230848/1237259]
Epoch 328
-------------------------------
loss: 0.013653 [ 2048/1237259]
loss: 0.013857 [206848/1237259]
loss: 0.012899 [411648/1237259]
loss: 0.011896 [616448/1237259]
loss: 0.012279 [821248/1237259]
loss: 0.013217 [1026048/1237259]
loss: 0.013212 [1230848/1237259]
Epoch 329
-------------------------------
loss: 0.013740 [ 2048/1237259]
loss: 0.011804 [206848/1237259]
loss: 0.013389 [411648/1237259]
loss: 0.013505 [616448/1237259]
loss: 0.012270 [821248/1237259]
loss: 0.013251 [1026048/1237259]
loss: 0.011997 [1230848/1237259]
Epoch 330
-------------------------------
loss: 0.014050 [ 2048/1237259]
loss: 0.013841 [206848/1237259]
loss: 0.011750 [411648/1237259]
loss: 0.013572 [616448/1237259]
loss: 0.014886 [821248/1237259]
loss: 0.011943 [1026048/1237259]
loss: 0.011293 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0604  
ndcg@20: 0.0488  
diversity: 0.1828  


Epoch 331
-------------------------------
loss: 0.014992 [ 2048/1237259]
loss: 0.012509 [206848/1237259]
loss: 0.013191 [411648/1237259]
loss: 0.012180 [616448/1237259]
loss: 0.013302 [821248/1237259]
loss: 0.015816 [1026048/1237259]
loss: 0.013082 [1230848/1237259]
Epoch 332
-------------------------------
loss: 0.011786 [ 2048/1237259]
loss: 0.012504 [206848/1237259]
loss: 0.013284 [411648/1237259]
loss: 0.012787 [616448/1237259]
loss: 0.012950 [821248/1237259]
loss: 0.013605 [1026048/1237259]
loss: 0.014645 [1230848/1237259]
Epoch 333
-------------------------------
loss: 0.013672 [ 2048/1237259]
loss: 0.014051 [206848/1237259]
loss: 0.016067 [411648/1237259]
loss: 0.012052 [616448/1237259]
loss: 0.013155 [821248/1237259]
loss: 0.013273 [1026048/1237259]
loss: 0.013311 [1230848/1237259]
Epoch 334
-------------------------------
loss: 0.013060 [ 2048/1237259]
loss: 0.013808 [206848/1237259]
loss: 0.012957 [411648/1237259]
loss: 0.013171 [616448/1237259]
loss: 0.013554 [821248/1237259]
loss: 0.013621 [1026048/1237259]
loss: 0.011974 [1230848/1237259]
Epoch 335
-------------------------------
loss: 0.013027 [ 2048/1237259]
loss: 0.012180 [206848/1237259]
loss: 0.012897 [411648/1237259]
loss: 0.012304 [616448/1237259]
loss: 0.012022 [821248/1237259]
loss: 0.012434 [1026048/1237259]
loss: 0.012964 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Eval results: 
recall@20: 0.0606  
ndcg@20: 0.0490  
diversity: 0.1827  


Epoch 336
-------------------------------
loss: 0.012938 [ 2048/1237259]
loss: 0.013189 [206848/1237259]
loss: 0.014226 [411648/1237259]
loss: 0.012426 [616448/1237259]
loss: 0.014100 [821248/1237259]
loss: 0.014631 [1026048/1237259]
loss: 0.013471 [1230848/1237259]
Epoch 337
-------------------------------
loss: 0.013035 [ 2048/1237259]
loss: 0.014119 [206848/1237259]
loss: 0.012550 [411648/1237259]
loss: 0.011817 [616448/1237259]
loss: 0.012645 [821248/1237259]
loss: 0.012668 [1026048/1237259]
loss: 0.014722 [1230848/1237259]
Epoch 338
-------------------------------
loss: 0.013991 [ 2048/1237259]
loss: 0.015232 [206848/1237259]
loss: 0.013277 [411648/1237259]
loss: 0.014472 [616448/1237259]
loss: 0.014320 [821248/1237259]
loss: 0.016124 [1026048/1237259]
loss: 0.013028 [1230848/1237259]
Epoch 339
-------------------------------
loss: 0.011814 [ 2048/1237259]
loss: 0.013503 [206848/1237259]
loss: 0.011625 [411648/1237259]
loss: 0.013454 [616448/1237259]
loss: 0.014125 [821248/1237259]
loss: 0.011579 [1026048/1237259]
loss: 0.012067 [1230848/1237259]
Epoch 340
-------------------------------
loss: 0.010593 [ 2048/1237259]
loss: 0.013650 [206848/1237259]
loss: 0.013455 [411648/1237259]
loss: 0.013511 [616448/1237259]
loss: 0.011695 [821248/1237259]
loss: 0.011555 [1026048/1237259]
loss: 0.012510 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0609  
ndcg@20: 0.0491  
diversity: 0.1828  


Epoch 341
-------------------------------
loss: 0.013498 [ 2048/1237259]
loss: 0.013471 [206848/1237259]
loss: 0.013332 [411648/1237259]
loss: 0.013529 [616448/1237259]
loss: 0.013284 [821248/1237259]
loss: 0.014305 [1026048/1237259]
loss: 0.012787 [1230848/1237259]
Epoch 342
-------------------------------
loss: 0.012149 [ 2048/1237259]
loss: 0.012248 [206848/1237259]
loss: 0.012855 [411648/1237259]
loss: 0.012714 [616448/1237259]
loss: 0.013063 [821248/1237259]
loss: 0.012470 [1026048/1237259]
loss: 0.012940 [1230848/1237259]
Epoch 343
-------------------------------
loss: 0.013448 [ 2048/1237259]
loss: 0.013072 [206848/1237259]
loss: 0.011878 [411648/1237259]
loss: 0.013515 [616448/1237259]
loss: 0.014371 [821248/1237259]
loss: 0.012440 [1026048/1237259]
loss: 0.014060 [1230848/1237259]
Epoch 344
-------------------------------
loss: 0.014659 [ 2048/1237259]
loss: 0.013444 [206848/1237259]
loss: 0.014014 [411648/1237259]
loss: 0.014701 [616448/1237259]
loss: 0.011638 [821248/1237259]
loss: 0.012096 [1026048/1237259]
loss: 0.013091 [1230848/1237259]
Epoch 345
-------------------------------
loss: 0.012314 [ 2048/1237259]
loss: 0.013358 [206848/1237259]
loss: 0.013366 [411648/1237259]
loss: 0.013672 [616448/1237259]
loss: 0.012380 [821248/1237259]
loss: 0.013700 [1026048/1237259]
loss: 0.013773 [1230848/1237259]
Best ndcg@20 model updated. Saving the model.
Eval results: 
recall@20: 0.0608  
ndcg@20: 0.0492  
diversity: 0.1827  


Epoch 346
-------------------------------
loss: 0.012245 [ 2048/1237259]
loss: 0.014427 [206848/1237259]
loss: 0.012720 [411648/1237259]
loss: 0.014474 [616448/1237259]
loss: 0.015103 [821248/1237259]
loss: 0.012677 [1026048/1237259]
loss: 0.014316 [1230848/1237259]
Epoch 347
-------------------------------
loss: 0.012369 [ 2048/1237259]
loss: 0.013184 [206848/1237259]
loss: 0.012983 [411648/1237259]
loss: 0.013197 [616448/1237259]
loss: 0.012436 [821248/1237259]
loss: 0.012878 [1026048/1237259]
loss: 0.012665 [1230848/1237259]
Epoch 348
-------------------------------
loss: 0.012857 [ 2048/1237259]
loss: 0.012366 [206848/1237259]
loss: 0.012276 [411648/1237259]
loss: 0.014106 [616448/1237259]
loss: 0.012918 [821248/1237259]
loss: 0.013492 [1026048/1237259]
loss: 0.012402 [1230848/1237259]
Epoch 349
-------------------------------
loss: 0.013897 [ 2048/1237259]
loss: 0.013716 [206848/1237259]
loss: 0.016299 [411648/1237259]
loss: 0.014204 [616448/1237259]
loss: 0.014305 [821248/1237259]
loss: 0.013020 [1026048/1237259]
loss: 0.013396 [1230848/1237259]
Epoch 350
-------------------------------
loss: 0.012513 [ 2048/1237259]
loss: 0.014191 [206848/1237259]
loss: 0.014987 [411648/1237259]
loss: 0.013428 [616448/1237259]
loss: 0.012096 [821248/1237259]
loss: 0.012503 [1026048/1237259]
loss: 0.013667 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0609  
ndcg@20: 0.0492  
diversity: 0.1830  


Epoch 351
-------------------------------
loss: 0.014863 [ 2048/1237259]
loss: 0.012250 [206848/1237259]
loss: 0.012471 [411648/1237259]
loss: 0.013087 [616448/1237259]
loss: 0.012157 [821248/1237259]
loss: 0.013365 [1026048/1237259]
loss: 0.012931 [1230848/1237259]
Epoch 352
-------------------------------
loss: 0.012939 [ 2048/1237259]
loss: 0.012740 [206848/1237259]
loss: 0.014004 [411648/1237259]
loss: 0.013471 [616448/1237259]
loss: 0.014454 [821248/1237259]
loss: 0.015328 [1026048/1237259]
loss: 0.011877 [1230848/1237259]
Epoch 353
-------------------------------
loss: 0.012385 [ 2048/1237259]
loss: 0.013844 [206848/1237259]
loss: 0.012862 [411648/1237259]
loss: 0.012301 [616448/1237259]
loss: 0.013496 [821248/1237259]
loss: 0.013443 [1026048/1237259]
loss: 0.013213 [1230848/1237259]
Epoch 354
-------------------------------
loss: 0.013181 [ 2048/1237259]
loss: 0.013082 [206848/1237259]
loss: 0.012500 [411648/1237259]
loss: 0.012640 [616448/1237259]
loss: 0.011339 [821248/1237259]
loss: 0.012693 [1026048/1237259]
loss: 0.013322 [1230848/1237259]
Epoch 355
-------------------------------
loss: 0.012304 [ 2048/1237259]
loss: 0.014281 [206848/1237259]
loss: 0.014438 [411648/1237259]
loss: 0.011336 [616448/1237259]
loss: 0.012744 [821248/1237259]
loss: 0.012520 [1026048/1237259]
loss: 0.012589 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Eval results: 
recall@20: 0.0609  
ndcg@20: 0.0492  
diversity: 0.1829  


Epoch 356
-------------------------------
loss: 0.013174 [ 2048/1237259]
loss: 0.012884 [206848/1237259]
loss: 0.011430 [411648/1237259]
loss: 0.015065 [616448/1237259]
loss: 0.011427 [821248/1237259]
loss: 0.013444 [1026048/1237259]
loss: 0.013066 [1230848/1237259]
Epoch 357
-------------------------------
loss: 0.013995 [ 2048/1237259]
loss: 0.012604 [206848/1237259]
loss: 0.011343 [411648/1237259]
loss: 0.014161 [616448/1237259]
loss: 0.013711 [821248/1237259]
loss: 0.014805 [1026048/1237259]
loss: 0.013791 [1230848/1237259]
Epoch 358
-------------------------------
loss: 0.014632 [ 2048/1237259]
loss: 0.012913 [206848/1237259]
loss: 0.014961 [411648/1237259]
loss: 0.014447 [616448/1237259]
loss: 0.012343 [821248/1237259]
loss: 0.014526 [1026048/1237259]
loss: 0.012726 [1230848/1237259]
Epoch 359
-------------------------------
loss: 0.014380 [ 2048/1237259]
loss: 0.011899 [206848/1237259]
loss: 0.012427 [411648/1237259]
loss: 0.012376 [616448/1237259]
loss: 0.013083 [821248/1237259]
loss: 0.013087 [1026048/1237259]
loss: 0.013249 [1230848/1237259]
Epoch 360
-------------------------------
loss: 0.012282 [ 2048/1237259]
loss: 0.014739 [206848/1237259]
loss: 0.012783 [411648/1237259]
loss: 0.011073 [616448/1237259]
loss: 0.012879 [821248/1237259]
loss: 0.013338 [1026048/1237259]
loss: 0.013156 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0610  
ndcg@20: 0.0494  
diversity: 0.1830  


Epoch 361
-------------------------------
loss: 0.015060 [ 2048/1237259]
loss: 0.011923 [206848/1237259]
loss: 0.014258 [411648/1237259]
loss: 0.013846 [616448/1237259]
loss: 0.013621 [821248/1237259]
loss: 0.010868 [1026048/1237259]
loss: 0.015595 [1230848/1237259]
Epoch 362
-------------------------------
loss: 0.013247 [ 2048/1237259]
loss: 0.013232 [206848/1237259]
loss: 0.012063 [411648/1237259]
loss: 0.010755 [616448/1237259]
loss: 0.014268 [821248/1237259]
loss: 0.013425 [1026048/1237259]
loss: 0.011977 [1230848/1237259]
Epoch 363
-------------------------------
loss: 0.012902 [ 2048/1237259]
loss: 0.012584 [206848/1237259]
loss: 0.013519 [411648/1237259]
loss: 0.011862 [616448/1237259]
loss: 0.012341 [821248/1237259]
loss: 0.012102 [1026048/1237259]
loss: 0.013319 [1230848/1237259]
Epoch 364
-------------------------------
loss: 0.013432 [ 2048/1237259]
loss: 0.013602 [206848/1237259]
loss: 0.012196 [411648/1237259]
loss: 0.012282 [616448/1237259]
loss: 0.013612 [821248/1237259]
loss: 0.012885 [1026048/1237259]
loss: 0.013646 [1230848/1237259]
Epoch 365
-------------------------------
loss: 0.015777 [ 2048/1237259]
loss: 0.012575 [206848/1237259]
loss: 0.014996 [411648/1237259]
loss: 0.013204 [616448/1237259]
loss: 0.012097 [821248/1237259]
loss: 0.012817 [1026048/1237259]
loss: 0.012477 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0613  
ndcg@20: 0.0495  
diversity: 0.1831  


Epoch 366
-------------------------------
loss: 0.012544 [ 2048/1237259]
loss: 0.013785 [206848/1237259]
loss: 0.013774 [411648/1237259]
loss: 0.013838 [616448/1237259]
loss: 0.012937 [821248/1237259]
loss: 0.010795 [1026048/1237259]
loss: 0.013950 [1230848/1237259]
Epoch 367
-------------------------------
loss: 0.011810 [ 2048/1237259]
loss: 0.012826 [206848/1237259]
loss: 0.012191 [411648/1237259]
loss: 0.012848 [616448/1237259]
loss: 0.012982 [821248/1237259]
loss: 0.013553 [1026048/1237259]
loss: 0.013080 [1230848/1237259]
Epoch 368
-------------------------------
loss: 0.015998 [ 2048/1237259]
loss: 0.013051 [206848/1237259]
loss: 0.014049 [411648/1237259]
loss: 0.013137 [616448/1237259]
loss: 0.013953 [821248/1237259]
loss: 0.013642 [1026048/1237259]
loss: 0.011142 [1230848/1237259]
Epoch 369
-------------------------------
loss: 0.012670 [ 2048/1237259]
loss: 0.012704 [206848/1237259]
loss: 0.012403 [411648/1237259]
loss: 0.013927 [616448/1237259]
loss: 0.014379 [821248/1237259]
loss: 0.011914 [1026048/1237259]
loss: 0.013309 [1230848/1237259]
Epoch 370
-------------------------------
loss: 0.010999 [ 2048/1237259]
loss: 0.012078 [206848/1237259]
loss: 0.012028 [411648/1237259]
loss: 0.013668 [616448/1237259]
loss: 0.014564 [821248/1237259]
loss: 0.014357 [1026048/1237259]
loss: 0.013052 [1230848/1237259]
Eval results: 
recall@20: 0.0611  
ndcg@20: 0.0494  
diversity: 0.1830  


Epoch 371
-------------------------------
loss: 0.012145 [ 2048/1237259]
loss: 0.013615 [206848/1237259]
loss: 0.012700 [411648/1237259]
loss: 0.011505 [616448/1237259]
loss: 0.013042 [821248/1237259]
loss: 0.014968 [1026048/1237259]
loss: 0.013420 [1230848/1237259]
Epoch 372
-------------------------------
loss: 0.011809 [ 2048/1237259]
loss: 0.012770 [206848/1237259]
loss: 0.013503 [411648/1237259]
loss: 0.012946 [616448/1237259]
loss: 0.013119 [821248/1237259]
loss: 0.013520 [1026048/1237259]
loss: 0.014611 [1230848/1237259]
Epoch 373
-------------------------------
loss: 0.013505 [ 2048/1237259]
loss: 0.014254 [206848/1237259]
loss: 0.012600 [411648/1237259]
loss: 0.013751 [616448/1237259]
loss: 0.010943 [821248/1237259]
loss: 0.013186 [1026048/1237259]
loss: 0.014222 [1230848/1237259]
Epoch 374
-------------------------------
loss: 0.013270 [ 2048/1237259]
loss: 0.012668 [206848/1237259]
loss: 0.012913 [411648/1237259]
loss: 0.015223 [616448/1237259]
loss: 0.013013 [821248/1237259]
loss: 0.013116 [1026048/1237259]
loss: 0.014310 [1230848/1237259]
Epoch 375
-------------------------------
loss: 0.012004 [ 2048/1237259]
loss: 0.011635 [206848/1237259]
loss: 0.014190 [411648/1237259]
loss: 0.012160 [616448/1237259]
loss: 0.011158 [821248/1237259]
loss: 0.013012 [1026048/1237259]
loss: 0.013191 [1230848/1237259]
Best recall@20 model updated. Saving the model.
Best ndcg@20 model updated. Saving the model.
Eval results: 
recall@20: 0.0614  
ndcg@20: 0.0496  
diversity: 0.1830  


Epoch 376
-------------------------------
loss: 0.012912 [ 2048/1237259]
loss: 0.012596 [206848/1237259]
loss: 0.013163 [411648/1237259]
loss: 0.011970 [616448/1237259]
loss: 0.012491 [821248/1237259]
loss: 0.012838 [1026048/1237259]
loss: 0.013370 [1230848/1237259]
Epoch 377
-------------------------------
loss: 0.013475 [ 2048/1237259]
loss: 0.012347 [206848/1237259]
loss: 0.012940 [411648/1237259]
loss: 0.012458 [616448/1237259]
loss: 0.013913 [821248/1237259]
loss: 0.013859 [1026048/1237259]
loss: 0.013742 [1230848/1237259]
Epoch 378
-------------------------------
loss: 0.012002 [ 2048/1237259]
loss: 0.012373 [206848/1237259]
loss: 0.013256 [411648/1237259]
loss: 0.013047 [616448/1237259]
loss: 0.012883 [821248/1237259]
loss: 0.012672 [1026048/1237259]
loss: 0.012186 [1230848/1237259]
Epoch 379
-------------------------------
loss: 0.013087 [ 2048/1237259]
loss: 0.012810 [206848/1237259]
loss: 0.012193 [411648/1237259]
loss: 0.013416 [616448/1237259]
loss: 0.014066 [821248/1237259]
loss: 0.012838 [1026048/1237259]
loss: 0.011486 [1230848/1237259]
Epoch 380
-------------------------------
loss: 0.012183 [ 2048/1237259]
loss: 0.013155 [206848/1237259]
loss: 0.014381 [411648/1237259]
loss: 0.011437 [616448/1237259]
loss: 0.013423 [821248/1237259]
loss: 0.013241 [1026048/1237259]
loss: 0.014172 [1230848/1237259]
Eval results: 
recall@20: 0.0610  
ndcg@20: 0.0494  
diversity: 0.1830  


Epoch 381
-------------------------------
loss: 0.012157 [ 2048/1237259]
loss: 0.012117 [206848/1237259]
loss: 0.012270 [411648/1237259]
loss: 0.011928 [616448/1237259]
loss: 0.011911 [821248/1237259]
loss: 0.012081 [1026048/1237259]
loss: 0.013113 [1230848/1237259]
Epoch 382
-------------------------------
loss: 0.012574 [ 2048/1237259]
loss: 0.011897 [206848/1237259]
loss: 0.012943 [411648/1237259]
loss: 0.013124 [616448/1237259]
loss: 0.013270 [821248/1237259]
loss: 0.011435 [1026048/1237259]
loss: 0.014688 [1230848/1237259]
Epoch 383
-------------------------------
loss: 0.013340 [ 2048/1237259]
loss: 0.012971 [206848/1237259]
loss: 0.013044 [411648/1237259]
loss: 0.011652 [616448/1237259]
loss: 0.013559 [821248/1237259]
loss: 0.013863 [1026048/1237259]
loss: 0.012044 [1230848/1237259]
Epoch 384
-------------------------------
loss: 0.014125 [ 2048/1237259]
loss: 0.013537 [206848/1237259]
loss: 0.011332 [411648/1237259]
loss: 0.012921 [616448/1237259]
loss: 0.013749 [821248/1237259]
loss: 0.014468 [1026048/1237259]
loss: 0.012291 [1230848/1237259]
Epoch 385
-------------------------------
loss: 0.013079 [ 2048/1237259]
loss: 0.013770 [206848/1237259]
loss: 0.013516 [411648/1237259]
loss: 0.011807 [616448/1237259]
loss: 0.015074 [821248/1237259]
loss: 0.013377 [1026048/1237259]
loss: 0.012940 [1230848/1237259]
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0609  
ndcg@20: 0.0494  
diversity: 0.1831  


Epoch 386
-------------------------------
loss: 0.013478 [ 2048/1237259]
loss: 0.011934 [206848/1237259]
loss: 0.013071 [411648/1237259]
loss: 0.013647 [616448/1237259]
loss: 0.013762 [821248/1237259]
loss: 0.012775 [1026048/1237259]
loss: 0.012181 [1230848/1237259]
Epoch 387
-------------------------------
loss: 0.012643 [ 2048/1237259]
loss: 0.014763 [206848/1237259]
loss: 0.013492 [411648/1237259]
loss: 0.013155 [616448/1237259]
loss: 0.012589 [821248/1237259]
loss: 0.013524 [1026048/1237259]
loss: 0.013067 [1230848/1237259]
Epoch 388
-------------------------------
loss: 0.010939 [ 2048/1237259]
loss: 0.010865 [206848/1237259]
loss: 0.013408 [411648/1237259]
loss: 0.011509 [616448/1237259]
loss: 0.014330 [821248/1237259]
loss: 0.012540 [1026048/1237259]
loss: 0.013862 [1230848/1237259]
Epoch 389
-------------------------------
loss: 0.011272 [ 2048/1237259]
loss: 0.013033 [206848/1237259]
loss: 0.013465 [411648/1237259]
loss: 0.014530 [616448/1237259]
loss: 0.012451 [821248/1237259]
loss: 0.012969 [1026048/1237259]
loss: 0.012264 [1230848/1237259]
Epoch 390
-------------------------------
loss: 0.011524 [ 2048/1237259]
loss: 0.012546 [206848/1237259]
loss: 0.014493 [411648/1237259]
loss: 0.013517 [616448/1237259]
loss: 0.013910 [821248/1237259]
loss: 0.011707 [1026048/1237259]
loss: 0.012035 [1230848/1237259]
Eval results: 
recall@20: 0.0613  
ndcg@20: 0.0495  
diversity: 0.1830  


Epoch 391
-------------------------------
loss: 0.012632 [ 2048/1237259]
loss: 0.013445 [206848/1237259]
loss: 0.011625 [411648/1237259]
loss: 0.014165 [616448/1237259]
loss: 0.013790 [821248/1237259]
loss: 0.013238 [1026048/1237259]
loss: 0.013106 [1230848/1237259]
Epoch 392
-------------------------------
loss: 0.013495 [ 2048/1237259]
loss: 0.012483 [206848/1237259]
loss: 0.012349 [411648/1237259]
loss: 0.013129 [616448/1237259]
loss: 0.013781 [821248/1237259]
loss: 0.011871 [1026048/1237259]
loss: 0.014888 [1230848/1237259]
Epoch 393
-------------------------------
loss: 0.013975 [ 2048/1237259]
loss: 0.013244 [206848/1237259]
loss: 0.012150 [411648/1237259]
loss: 0.012967 [616448/1237259]
loss: 0.012450 [821248/1237259]
loss: 0.013376 [1026048/1237259]
loss: 0.013263 [1230848/1237259]
Epoch 394
-------------------------------
loss: 0.013122 [ 2048/1237259]
loss: 0.012956 [206848/1237259]
loss: 0.013308 [411648/1237259]
loss: 0.015735 [616448/1237259]
loss: 0.012419 [821248/1237259]
loss: 0.012899 [1026048/1237259]
loss: 0.013467 [1230848/1237259]
Epoch 395
-------------------------------
loss: 0.012677 [ 2048/1237259]
loss: 0.013089 [206848/1237259]
loss: 0.012941 [411648/1237259]
loss: 0.013238 [616448/1237259]
loss: 0.013029 [821248/1237259]
loss: 0.011747 [1026048/1237259]
loss: 0.013292 [1230848/1237259]
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0614  
ndcg@20: 0.0496  
diversity: 0.1832  


Epoch 396
-------------------------------
loss: 0.012237 [ 2048/1237259]
loss: 0.013025 [206848/1237259]
loss: 0.012978 [411648/1237259]
loss: 0.013907 [616448/1237259]
loss: 0.013993 [821248/1237259]
loss: 0.012757 [1026048/1237259]
loss: 0.013461 [1230848/1237259]
Epoch 397
-------------------------------
loss: 0.011328 [ 2048/1237259]
loss: 0.013905 [206848/1237259]
loss: 0.011770 [411648/1237259]
loss: 0.014118 [616448/1237259]
loss: 0.013897 [821248/1237259]
loss: 0.013547 [1026048/1237259]
loss: 0.012039 [1230848/1237259]
Epoch 398
-------------------------------
loss: 0.012875 [ 2048/1237259]
loss: 0.013959 [206848/1237259]
loss: 0.012840 [411648/1237259]
loss: 0.011186 [616448/1237259]
loss: 0.012829 [821248/1237259]
loss: 0.013088 [1026048/1237259]
loss: 0.011883 [1230848/1237259]
Epoch 399
-------------------------------
loss: 0.011558 [ 2048/1237259]
loss: 0.013984 [206848/1237259]
loss: 0.012064 [411648/1237259]
loss: 0.013160 [616448/1237259]
loss: 0.011952 [821248/1237259]
loss: 0.012881 [1026048/1237259]
loss: 0.013474 [1230848/1237259]
Epoch 400
-------------------------------
loss: 0.012519 [ 2048/1237259]
loss: 0.013253 [206848/1237259]
loss: 0.012751 [411648/1237259]
loss: 0.013176 [616448/1237259]
loss: 0.010860 [821248/1237259]
loss: 0.013259 [1026048/1237259]
loss: 0.012572 [1230848/1237259]
Best diversity model updated. Saving the model.
Eval results: 
recall@20: 0.0610  
ndcg@20: 0.0494  
diversity: 0.1833  


Epoch 401
-------------------------------
loss: 0.011433 [ 2048/1237259]
loss: 0.012459 [206848/1237259]
loss: 0.011718 [411648/1237259]
loss: 0.013418 [616448/1237259]
loss: 0.012686 [821248/1237259]
loss: 0.011723 [1026048/1237259]
loss: 0.013282 [1230848/1237259]
Epoch 402
-------------------------------
loss: 0.011560 [ 2048/1237259]
loss: 0.012388 [206848/1237259]
loss: 0.012405 [411648/1237259]
loss: 0.013261 [616448/1237259]
loss: 0.012350 [821248/1237259]
loss: 0.013052 [1026048/1237259]
loss: 0.011873 [1230848/1237259]
Epoch 403
-------------------------------
loss: 0.013054 [ 2048/1237259]
loss: 0.011823 [206848/1237259]
loss: 0.012186 [411648/1237259]
loss: 0.013098 [616448/1237259]
loss: 0.012988 [821248/1237259]
loss: 0.012427 [1026048/1237259]
loss: 0.012281 [1230848/1237259]
Epoch 404
-------------------------------
loss: 0.014585 [ 2048/1237259]
loss: 0.013686 [206848/1237259]
loss: 0.012984 [411648/1237259]
loss: 0.012105 [616448/1237259]
loss: 0.013942 [821248/1237259]
loss: 0.012873 [1026048/1237259]
loss: 0.010840 [1230848/1237259]
Epoch 405
-------------------------------
loss: 0.013249 [ 2048/1237259]
loss: 0.012435 [206848/1237259]
loss: 0.012828 [411648/1237259]
loss: 0.011097 [616448/1237259]
loss: 0.012700 [821248/1237259]
loss: 0.012450 [1026048/1237259]
loss: 0.013241 [1230848/1237259]
Eval results: 
recall@20: 0.0612  
ndcg@20: 0.0496  
diversity: 0.1833  


Epoch 406
-------------------------------
loss: 0.014226 [ 2048/1237259]
loss: 0.012236 [206848/1237259]
loss: 0.013948 [411648/1237259]
loss: 0.014153 [616448/1237259]
