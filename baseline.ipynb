{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23540,
     "status": "ok",
     "timestamp": 1733321873273,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "hhgZo2hhEVux",
    "outputId": "4d9c4c4b-f74b-4437-aaca-bc4ee7ac74c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Colab.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Google Drive is mounted successfully for Colab.')\n",
    "except:\n",
    "    print('Not Colab.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 4340,
     "status": "ok",
     "timestamp": 1733321877598,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "f4rusa7q0gfX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse as sp\n",
    "from time import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1733321877599,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "Y8shxep-9xP9"
   },
   "outputs": [],
   "source": [
    "# CAUTION - Set your options #\n",
    "sys.dont_write_bytecode = True  # pycahce option\n",
    "\n",
    "# Put yelp2018 raw data directory path.\n",
    "\n",
    "# colab\n",
    "# path: str = '/content/drive/MyDrive/projects/기초추천시스템/model'\n",
    "# local\n",
    "path: str = (\n",
    "    \"/Users/june/projects/기초추천시스템/diversity-enhanced-lightgcn/model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1733321877599,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "QdCwf9Lb-ikH"
   },
   "outputs": [],
   "source": [
    "# Your Environment Setting #\n",
    "os.chdir(path)\n",
    "train_file = path + \"/yelp2018/train.txt\"\n",
    "test_file = path + \"/yelp2018/test.txt\"\n",
    "adj_mat_file = path + \"/yelp2018/s_pre_adj_mat.npz\"\n",
    "\n",
    "assert os.getcwd() == path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1733321877599,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "G_ENgKUq-dIP",
    "outputId": "2744e656-3ce7-45f3-d5d3-b9dd5dc5af77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Training Resource Check #\n",
    "device_str = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    # else \"mps\"\n",
    "    # if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Your Device: {device_str}\")\n",
    "\n",
    "device = torch.device(device_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1047,
     "status": "ok",
     "timestamp": 1733328516374,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "ny3ajIAhB-xJ"
   },
   "outputs": [],
   "source": [
    "# Important settings including loss function, training epochs, etc.\n",
    "\n",
    "# PARAMETERS\n",
    "\n",
    "# Data\n",
    "TRAIN_BATCH_SIZE = 1024\n",
    "TEST_BATCH_SIZE = 2048\n",
    "DO_NEG_SAMPLING = False\n",
    "\n",
    "# Loss\n",
    "from loss import loss_dict\n",
    "\n",
    "# LOSS_FN = \"directau\"\n",
    "LOSS_FN = \"deweighted_directau\"\n",
    "assert LOSS_FN in loss_dict\n",
    "\n",
    "# Training\n",
    "EPOCHS = 500\n",
    "\n",
    "# Model\n",
    "N_LAYERS = 3\n",
    "EMBEDDING_DIM = 64\n",
    "\n",
    "# Evaluation\n",
    "TOP_K = 20\n",
    "METRICS = [\"recall\", \"ndcg\", \"diversity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Preferences\n",
    "\n",
    "# Get the current date and time\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "RESULT_DIR = path + \"/result\"\n",
    "# File path to save the best models\n",
    "BEST_MODEL_BASE_DIR = RESULT_DIR + f\"/{current_time}_best_model\"\n",
    "\n",
    "# Text file to save the metric history\n",
    "METRIC_RESULTS_FILE = RESULT_DIR + f\"/{current_time}_metric.tsv\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(BEST_MODEL_BASE_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(METRIC_RESULTS_FILE), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4TsmHwavdB1"
   },
   "source": [
    "# **Part1.** Data Pipeline\n",
    "\n",
    "**`class Yelp2018`**  \n",
    "> **Initialize** `(train_file, test_file)`  \n",
    "\n",
    "*.txt 확장자인 Yelp2018 raw 데이터를 학습이 용이하도록 전처리\n",
    "\n",
    "\\\\\n",
    "\n",
    "**`class AdjacencyMatrix`** \\\\\n",
    "> **Initialize** `(train_user, train_item, num_user, num_item, device)`\n",
    "\n",
    "전처리한 학습 데이터를 기반으로 Normalized Adjacency Matrix를 구축  \n",
    "특히, `get_sparse_graph(adj_mat_file)`의 반환값은 Normalized Adjacency Matrix임에 유의하며  \n",
    "이는 논문에서 $\\tilde{\\mathbf{A}} := \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}}$ 이다.\n",
    "\n",
    "\\\\\n",
    "\n",
    "**`class PairwiseTrainData(torch.utils.dataset)`** \\\\\n",
    "> **Initialize** `(train_user, train_item, num_user, num_item)`  \n",
    "\n",
    "전처리한 학습 데이터를 기반으로 BPR Loss 학습을 위한 Negative Sampling 과정을 구현\n",
    "\n",
    "\\\\\n",
    "\n",
    "**`class TestData(torch.utils.dataset)`** \\\\\n",
    "> **Initialize** `(train_user, train_item, test_user, test_item)`  \n",
    "\n",
    "전처리한 학습 데이터와 테스트 데이터를 기반으로 구현  \n",
    "특히, 추천시스템의 Metric의 특성 때문에 학습 데이터에서 본 아이템은 랭킹에서 제외해야한다.  \n",
    "따라서 학습 데이터도 사용해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 1124,
     "status": "ok",
     "timestamp": 1733328552826,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "GFaXN3iKuadP"
   },
   "outputs": [],
   "source": [
    "from data_utils import Yelp2018\n",
    "\n",
    "yelp2018 = Yelp2018(train_file, test_file)\n",
    "\n",
    "num_user = yelp2018.num_user\n",
    "num_item = yelp2018.num_item\n",
    "\n",
    "train_user = yelp2018.train_user\n",
    "train_item = yelp2018.train_item\n",
    "train_interaction = yelp2018.train_interaction\n",
    "\n",
    "test_user = yelp2018.test_user\n",
    "test_item = yelp2018.test_item\n",
    "test_interaction = yelp2018.test_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1733328552826,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "u9KUakgyBJOU",
    "outputId": "84410ef0-d871-4101-da74-d85f0cc84a0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yelp2018\n",
      "\n",
      "#user = 31668\n",
      "#item = 38048\n",
      "\n",
      "#interactions\n",
      "    (train) 1237259\n",
      "    (test)  324147\n",
      "    (total) 1561406\n",
      "\n",
      "Sparsity = 0.0012958757851778645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Yelp2018 Statistics Check #\n",
    "print(\"Yelp2018\")\n",
    "print(\n",
    "    f\"\"\"\n",
    "#user = {num_user}\n",
    "#item = {num_item}\n",
    "\n",
    "#interactions\n",
    "    (train) {train_interaction}\n",
    "    (test)  {test_interaction}\n",
    "    (total) {train_interaction + test_interaction}\n",
    "\n",
    "Sparsity = {(train_interaction + test_interaction) / (num_user * num_item)}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1461,
     "status": "ok",
     "timestamp": 1733328554280,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "dNVnhMeSju27",
    "outputId": "93d55ade-cf3a-496a-96b0-9726d90d3dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading adjacency matrix\n",
      "successfully loaded...\n",
      "don't split the matrix\n"
     ]
    }
   ],
   "source": [
    "from data_utils import AdjacencyMatrix\n",
    "\n",
    "adjacency_matrix = AdjacencyMatrix(train_user, train_item, num_user, num_item, device)\n",
    "graph = adjacency_matrix.get_sparse_graph(\n",
    "    adj_mat_file\n",
    ")  # This is The Normalized Adjacency Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1733328554280,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "08dvm6V-UbTV"
   },
   "outputs": [],
   "source": [
    "from data_utils import PairwiseTrainData\n",
    "\n",
    "train_dataset = PairwiseTrainData(\n",
    "    train_user, train_item, num_user, num_item, do_neg_sampling=DO_NEG_SAMPLING\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1733328554280,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "SLPx9WSfB-xT"
   },
   "outputs": [],
   "source": [
    "train_test_user = np.concatenate([train_user, test_user])\n",
    "train_test_item = np.concatenate([train_item, test_item])\n",
    "\n",
    "# Get degree per item for use in the top-k metric calculation\n",
    "train_test_item_degree = torch.tensor(\n",
    "    np.bincount(train_test_item), dtype=torch.float32\n",
    ").to(device)\n",
    "\n",
    "# Get degree per item only in the train set for use in the loss function while training\n",
    "train_item_degree = torch.tensor(np.bincount(train_item), dtype=torch.float32).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "del train_test_user, train_test_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part 2**. Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1733328554280,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "d8e6DuKsB-xT",
    "outputId": "fd0b42cb-0701-4e4d-e121-9bb95e02eb7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGCN(\n",
       "  (user_embedding): Embedding(31668, 64)\n",
       "  (item_embedding): Embedding(38048, 64)\n",
       "  (f): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "\n",
    "from model import LightGCN\n",
    "\n",
    "model = LightGCN(num_user, num_item, N_LAYERS, EMBEDDING_DIM, graph)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1139,
     "status": "ok",
     "timestamp": 1733328681828,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "XVV-HoE-WKik"
   },
   "outputs": [],
   "source": [
    "def train_loop(train_dataloader, model, loss_fn, optimizer: torch.optim.Optimizer):\n",
    "    model.train()\n",
    "\n",
    "    loss_sum = 0\n",
    "\n",
    "    size = len(train_dataloader.dataset)\n",
    "    num_batches = len(train_dataloader)\n",
    "\n",
    "    for batch_num, minibatch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        user:           torch.Tensor = minibatch[0].to(device)\n",
    "        pos_item:       torch.Tensor = minibatch[1].to(device)\n",
    "        if DO_NEG_SAMPLING:\n",
    "            neg_item:   torch.Tensor = minibatch[2].to(device)\n",
    "\n",
    "        if DO_NEG_SAMPLING:\n",
    "            result = model(user, pos_item, neg_items=neg_item)\n",
    "        else:\n",
    "            result = model(user, pos_item)\n",
    "\n",
    "        loss = loss_fn(**result, pos_item=pos_item)\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_num % 100 == 0:\n",
    "            print(\n",
    "                f\"loss: {loss.item():>7f} [{TRAIN_BATCH_SIZE * batch_num + len(minibatch[0]):>5d}/{size:>5d}]\"\n",
    "            )\n",
    "\n",
    "    avg_loss = loss_sum / num_batches\n",
    "    print(f\"Train Avg loss: {avg_loss:>7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary to store the best metric values along epochs\n",
    "best_metric = dict()\n",
    "\n",
    "# Boolean indicating whether to write the header in the metric file\n",
    "write_header = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1733328554280,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "s-4KblDpB-xT"
   },
   "outputs": [],
   "source": [
    "from evaluator import TopKEvaluator\n",
    "from data_utils import remove_padding\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, evaluator: TopKEvaluator, epoch: int):\n",
    "    global best_metric, write_header\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    metrics_result_dict = dict()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for minibatch in tqdm(dataloader):\n",
    "            user:       torch.Tensor = minibatch[0].to(device)\n",
    "            history:    torch.Tensor = minibatch[1].to(device)  # 각 유저 별 train 에서 존재하는 아이템\n",
    "            label:      torch.Tensor = minibatch[2].to(device)  # 각 유저 별 test  에서 존재하는 아이템\n",
    "\n",
    "            history:    list[torch.Tensor] = remove_padding(history)\n",
    "            label:      list[torch.Tensor] = remove_padding(label)\n",
    "\n",
    "            pred:       torch.Tensor = model.get_users_rating_prediction(user)\n",
    "            assert pred.shape == (len(user), num_item)\n",
    "\n",
    "            result_dict = evaluator.evaluate(pred, history, label)\n",
    "            for metric in result_dict:\n",
    "                if metric not in metrics_result_dict:\n",
    "                    metrics_result_dict[metric] = 0\n",
    "                metrics_result_dict[metric] += result_dict[metric]\n",
    "\n",
    "    for metric in metrics_result_dict:\n",
    "        metrics_result_dict[metric] /= num_batches\n",
    "\n",
    "    # Save metrics to a text file\n",
    "    with open(METRIC_RESULTS_FILE, \"a\") as f:\n",
    "        if write_header:\n",
    "            f.write(\"epoch\\t\")\n",
    "            for metric in metrics_result_dict:\n",
    "                f.write(f\"{metric}\\t\")\n",
    "            f.write(\"\\n\")\n",
    "            write_header = False\n",
    "\n",
    "        f.write(f\"{epoch}\\t\")\n",
    "        for metric in metrics_result_dict:\n",
    "            f.write(f\"{metrics_result_dict[metric]:.4f}\\t\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # Check and save the best models\n",
    "    for metric in metrics_result_dict:\n",
    "        if metric not in best_metric:\n",
    "            best_metric[metric] = 0\n",
    "        if metrics_result_dict[metric] > best_metric[metric]:\n",
    "            best_metric[metric] = metrics_result_dict[metric]\n",
    "            print(f\"Best {metric} model updated. Saving the model.\")\n",
    "            torch.save(\n",
    "                model.state_dict(), f\"{BEST_MODEL_BASE_DIR}/best_{metric}_model.pth\"\n",
    "            )\n",
    "\n",
    "    print(f\"Eval results: \")\n",
    "    for metric in metrics_result_dict:\n",
    "        print(f\"{metric}: {metrics_result_dict[metric]:.4f}\", end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1733328554280,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "Ccnd4tT2B-xU"
   },
   "outputs": [],
   "source": [
    "from loss import loss_dict\n",
    "\n",
    "loss_fn = loss_dict[LOSS_FN](item_degree=train_item_degree).loss_fn\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1733328554936,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "r_RIKCr2B-xU"
   },
   "outputs": [],
   "source": [
    "from data_utils import TestData, collate_fn\n",
    "\n",
    "test_dataset = TestData(train_user, train_item, test_user, test_item)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 646693,
     "status": "ok",
     "timestamp": 1733329334846,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "lzQJQzm6B-xU",
    "outputId": "2606e161-46d2-4eec-f933-ee155501ac57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: -3.474885 [ 1024/1237259]\n",
      "loss: -3.479510 [103424/1237259]\n",
      "loss: -3.482824 [205824/1237259]\n",
      "loss: -3.484504 [308224/1237259]\n",
      "loss: -3.482735 [410624/1237259]\n",
      "loss: -3.482762 [513024/1237259]\n",
      "loss: -3.488720 [615424/1237259]\n",
      "loss: -3.491537 [717824/1237259]\n",
      "loss: -3.486400 [820224/1237259]\n",
      "loss: -3.488761 [922624/1237259]\n",
      "loss: -3.493164 [1025024/1237259]\n",
      "loss: -3.494300 [1127424/1237259]\n",
      "loss: -3.497872 [1229824/1237259]\n",
      "Train Avg loss: -3.486905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:07<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best recall@20 model updated. Saving the model.\n",
      "Best ndcg@20 model updated. Saving the model.\n",
      "Best diversity model updated. Saving the model.\n",
      "Eval results: \n",
      "recall@20: 0.0061 ndcg@20: 0.0058 diversity: 0.2922 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: -3.503369 [ 1024/1237259]\n",
      "loss: -3.503481 [103424/1237259]\n",
      "loss: -3.511107 [205824/1237259]\n",
      "loss: -3.504750 [308224/1237259]\n",
      "loss: -3.503380 [410624/1237259]\n",
      "loss: -3.506535 [513024/1237259]\n",
      "loss: -3.512193 [615424/1237259]\n",
      "loss: -3.508759 [717824/1237259]\n",
      "loss: -3.511808 [820224/1237259]\n"
     ]
    }
   ],
   "source": [
    "from evaluator import TopKEvaluator\n",
    "\n",
    "evaluator = TopKEvaluator(\n",
    "    TOP_K, METRICS, device=device, item_degree=train_test_item_degree\n",
    ")\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn, evaluator, epoch)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
