{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23540,
     "status": "ok",
     "timestamp": 1733321873273,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "hhgZo2hhEVux",
    "outputId": "4d9c4c4b-f74b-4437-aaca-bc4ee7ac74c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Colab.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Google Drive is mounted successfully for Colab.')\n",
    "except:\n",
    "    print('Not Colab.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4340,
     "status": "ok",
     "timestamp": 1733321877598,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "f4rusa7q0gfX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse as sp\n",
    "from time import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1733321877599,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "Y8shxep-9xP9"
   },
   "outputs": [],
   "source": [
    "# CAUTION - Set your options #\n",
    "sys.dont_write_bytecode = True  # pycahce option\n",
    "\n",
    "# Put yelp2018 raw data directory path.\n",
    "\n",
    "# colab\n",
    "# path: str = '/content/drive/MyDrive/projects/기초추천시스템/model'\n",
    "# local\n",
    "path: str = (\n",
    "    \"/Users/june/projects/기초추천시스템/diversity-enhanced-lightgcn/model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1733321877599,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "QdCwf9Lb-ikH"
   },
   "outputs": [],
   "source": [
    "# Your Environment Setting #\n",
    "os.chdir(path)\n",
    "assert os.getcwd() == path\n",
    "\n",
    "import config\n",
    "\n",
    "train_file = config.train_file\n",
    "test_file = config.test_file\n",
    "adj_mat_file = config.adj_mat_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1733321877599,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "G_ENgKUq-dIP",
    "outputId": "2744e656-3ce7-45f3-d5d3-b9dd5dc5af77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Device: cpu\n"
     ]
    }
   ],
   "source": [
    "from logger import console\n",
    "\n",
    "# Training Resource Check #\n",
    "device_str = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    # else \"mps\"\n",
    "    # if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Your Device: {device_str}\")\n",
    "\n",
    "device = torch.device(device_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1047,
     "status": "ok",
     "timestamp": 1733328516374,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "ny3ajIAhB-xJ"
   },
   "outputs": [],
   "source": [
    "# Important settings including loss function, training epochs, etc. -> set them in config.py\n",
    "\n",
    "# PARAMETERS\n",
    "\n",
    "# Data\n",
    "TRAIN_BATCH_SIZE = config.train_batch_size\n",
    "TEST_BATCH_SIZE = config.test_batch_size\n",
    "DO_NEG_SAMPLING = config.do_neg_sampling\n",
    "\n",
    "# Loss\n",
    "from loss import loss_dict\n",
    "\n",
    "# LOSS_FN = \"directau\"\n",
    "LOSS_FN = config.loss_fn\n",
    "assert LOSS_FN in loss_dict\n",
    "\n",
    "reg_strength = config.reg_strength\n",
    "\n",
    "# Training\n",
    "EPOCHS = config.epochs\n",
    "\n",
    "# Model\n",
    "N_LAYERS = config.n_layers\n",
    "EMBEDDING_DIM = config.embed_dim\n",
    "\n",
    "# Evaluation\n",
    "TOP_K = config.topk\n",
    "METRICS = config.metrics\n",
    "\n",
    "# Set random seed\n",
    "from misc import set_seed\n",
    "\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Preferences\n",
    "\n",
    "# Get the current date and time\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# File path to save the best models\n",
    "BEST_MODEL_BASE_DIR = config.best_model_dir\n",
    "\n",
    "# Text file to save the metric history\n",
    "METRIC_RESULTS_FILE = config.metric_result_file\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(BEST_MODEL_BASE_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(METRIC_RESULTS_FILE), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4TsmHwavdB1"
   },
   "source": [
    "# **Part1.** Data Pipeline\n",
    "\n",
    "**`class Yelp2018`**  \n",
    "> **Initialize** `(train_file, test_file)`  \n",
    "\n",
    "*.txt 확장자인 Yelp2018 raw 데이터를 학습이 용이하도록 전처리\n",
    "\n",
    "\\\\\n",
    "\n",
    "**`class AdjacencyMatrix`** \\\\\n",
    "> **Initialize** `(train_user, train_item, num_user, num_item, device)`\n",
    "\n",
    "전처리한 학습 데이터를 기반으로 Normalized Adjacency Matrix를 구축  \n",
    "특히, `get_sparse_graph(adj_mat_file)`의 반환값은 Normalized Adjacency Matrix임에 유의하며  \n",
    "이는 논문에서 $\\tilde{\\mathbf{A}} := \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}}$ 이다.\n",
    "\n",
    "\\\\\n",
    "\n",
    "**`class PairwiseTrainData(torch.utils.dataset)`** \\\\\n",
    "> **Initialize** `(train_user, train_item, num_user, num_item)`  \n",
    "\n",
    "전처리한 학습 데이터를 기반으로 BPR Loss 학습을 위한 Negative Sampling 과정을 구현\n",
    "\n",
    "\\\\\n",
    "\n",
    "**`class TestData(torch.utils.dataset)`** \\\\\n",
    "> **Initialize** `(train_user, train_item, test_user, test_item)`  \n",
    "\n",
    "전처리한 학습 데이터와 테스트 데이터를 기반으로 구현  \n",
    "특히, 추천시스템의 Metric의 특성 때문에 학습 데이터에서 본 아이템은 랭킹에서 제외해야한다.  \n",
    "따라서 학습 데이터도 사용해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1124,
     "status": "ok",
     "timestamp": 1733328552826,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "GFaXN3iKuadP"
   },
   "outputs": [],
   "source": [
    "from data_utils import Yelp2018\n",
    "\n",
    "yelp2018 = Yelp2018(train_file, test_file)\n",
    "\n",
    "num_user = yelp2018.num_user\n",
    "num_item = yelp2018.num_item\n",
    "\n",
    "train_user = yelp2018.train_user\n",
    "train_item = yelp2018.train_item\n",
    "train_interaction = yelp2018.train_interaction\n",
    "\n",
    "test_user = yelp2018.test_user\n",
    "test_item = yelp2018.test_item\n",
    "test_interaction = yelp2018.test_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1733328552826,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "u9KUakgyBJOU",
    "outputId": "84410ef0-d871-4101-da74-d85f0cc84a0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yelp2018\n",
      "\n",
      "#user = 31668\n",
      "#item = 38048\n",
      "\n",
      "#interactions\n",
      "    (train) 1237259\n",
      "    (test)  324147\n",
      "    (total) 1561406\n",
      "\n",
      "Sparsity = 0.0012958757851778645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Yelp2018 Statistics Check #\n",
    "print(\"Yelp2018\")\n",
    "print(\n",
    "    f\"\"\"\n",
    "#user = {num_user}\n",
    "#item = {num_item}\n",
    "\n",
    "#interactions\n",
    "    (train) {train_interaction}\n",
    "    (test)  {test_interaction}\n",
    "    (total) {train_interaction + test_interaction}\n",
    "\n",
    "Sparsity = {(train_interaction + test_interaction) / (num_user * num_item)}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1461,
     "status": "ok",
     "timestamp": 1733328554280,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "dNVnhMeSju27",
    "outputId": "93d55ade-cf3a-496a-96b0-9726d90d3dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading adjacency matrix\n",
      "successfully loaded...\n",
      "don't split the matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/june/projects/기초추천시스템/diversity-enhanced-lightgcn/model/data_utils.py:113: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1732815791172/work/torch/csrc/utils/tensor_new.cpp:653.)\n",
      "  return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))\n"
     ]
    }
   ],
   "source": [
    "from data_utils import AdjacencyMatrix\n",
    "\n",
    "adjacency_matrix = AdjacencyMatrix(train_user, train_item, num_user, num_item, device)\n",
    "graph = adjacency_matrix.get_sparse_graph(\n",
    "    adj_mat_file\n",
    ")  # This is The Normalized Adjacency Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1733328554280,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "08dvm6V-UbTV"
   },
   "outputs": [],
   "source": [
    "from data_utils import PairwiseTrainData\n",
    "import misc\n",
    "\n",
    "train_dataset = PairwiseTrainData(\n",
    "    train_user, train_item, num_user, num_item, do_neg_sampling=DO_NEG_SAMPLING\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    worker_init_fn=misc.seed_worker,\n",
    "    generator=misc.get_generator(config.seed),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import TestData, collate_fn\n",
    "\n",
    "test_dataset = TestData(train_user, train_item, test_user, test_item)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    worker_init_fn=misc.seed_worker,\n",
    "    generator=misc.get_generator(config.seed),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1733328554280,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "SLPx9WSfB-xT"
   },
   "outputs": [],
   "source": [
    "train_test_user = np.concatenate([train_user, test_user])\n",
    "train_test_item = np.concatenate([train_item, test_item])\n",
    "\n",
    "# Get degree per item for use in the top-k metric calculation\n",
    "train_test_item_degree = torch.tensor(\n",
    "    np.bincount(train_test_item), dtype=torch.float32\n",
    ").to(device)\n",
    "\n",
    "# Get degree per item only in the train set for use in the loss function while training\n",
    "train_item_degree = torch.tensor(np.bincount(train_item), dtype=torch.float32).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "del train_test_user, train_test_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part 2**. Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1733328554280,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "d8e6DuKsB-xT",
    "outputId": "fd0b42cb-0701-4e4d-e121-9bb95e02eb7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGCN(\n",
       "  (user_embedding): Embedding(31668, 64)\n",
       "  (item_embedding): Embedding(38048, 64)\n",
       "  (f): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "\n",
    "from model import LightGCN\n",
    "\n",
    "model = LightGCN(num_user, num_item, N_LAYERS, EMBEDDING_DIM, graph)\n",
    "if config.load_model:\n",
    "    model.load_state_dict(torch.load(config.model_file, weights_only=True))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1139,
     "status": "ok",
     "timestamp": 1733328681828,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "XVV-HoE-WKik"
   },
   "outputs": [],
   "source": [
    "def train_loop(train_dataloader, model, loss_fn, optimizer: torch.optim.Optimizer):\n",
    "    model.train()\n",
    "\n",
    "    loss_sum = 0\n",
    "\n",
    "    size = len(train_dataloader.dataset)\n",
    "    num_batches = len(train_dataloader)\n",
    "\n",
    "    for batch_num, minibatch in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        user: torch.Tensor = minibatch[0].to(device)\n",
    "        pos_item: torch.Tensor = minibatch[1].to(device)\n",
    "        if DO_NEG_SAMPLING:\n",
    "            neg_item: torch.Tensor = minibatch[2].to(device)\n",
    "\n",
    "        if DO_NEG_SAMPLING:\n",
    "            result = model(user, pos_item, neg_items=neg_item)\n",
    "        else:\n",
    "            result = model(user, pos_item)\n",
    "\n",
    "        loss = loss_fn(**result, pos_item=pos_item)\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_num % 100 == 0:\n",
    "            console(\n",
    "                f\"loss: {loss.item():>7f} [{TRAIN_BATCH_SIZE * batch_num + len(minibatch[0]):>5d}/{size:>5d}]\"\n",
    "            )\n",
    "\n",
    "    avg_loss = loss_sum / num_batches\n",
    "    console(f\"Train Avg loss: {avg_loss:>7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary to store the best metric values along epochs\n",
    "best_metric = dict()\n",
    "\n",
    "# Boolean indicating whether to write the header in the metric file\n",
    "write_header = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1733328554280,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "s-4KblDpB-xT"
   },
   "outputs": [],
   "source": [
    "from evaluator import TopKEvaluator\n",
    "from data_utils import remove_padding\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, evaluator: TopKEvaluator, epoch: int):\n",
    "    global best_metric, write_header\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    metrics_result_dict = dict()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for minibatch in tqdm(dataloader):\n",
    "            user: torch.Tensor = minibatch[0].to(device)\n",
    "            history: torch.Tensor = minibatch[1].to(\n",
    "                device\n",
    "            )  # 각 유저 별 train 에서 존재하는 아이템\n",
    "            label: torch.Tensor = minibatch[2].to(\n",
    "                device\n",
    "            )  # 각 유저 별 test  에서 존재하는 아이템\n",
    "\n",
    "            history: list[torch.Tensor] = remove_padding(history)\n",
    "            label: list[torch.Tensor] = remove_padding(label)\n",
    "\n",
    "            pred: torch.Tensor = model.get_users_rating_prediction(user)\n",
    "            assert pred.shape == (len(user), num_item)\n",
    "\n",
    "            result_dict = evaluator.evaluate(pred, history, label)\n",
    "            for metric in result_dict:\n",
    "                if metric not in metrics_result_dict:\n",
    "                    metrics_result_dict[metric] = 0\n",
    "                metrics_result_dict[metric] += result_dict[metric]\n",
    "\n",
    "    for metric in metrics_result_dict:\n",
    "        metrics_result_dict[metric] /= num_batches\n",
    "\n",
    "    # Save metrics to a text file\n",
    "    with open(METRIC_RESULTS_FILE, \"a\") as f:\n",
    "        if write_header:\n",
    "            f.write(\"epoch\\t\")\n",
    "            for metric in metrics_result_dict:\n",
    "                f.write(f\"{metric}\\t\")\n",
    "            f.write(\"\\n\")\n",
    "            write_header = False\n",
    "\n",
    "        f.write(f\"{epoch}\\t\")\n",
    "        for metric in metrics_result_dict:\n",
    "            f.write(f\"{metrics_result_dict[metric]:.4f}\\t\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # Check and save the best models\n",
    "    for metric in metrics_result_dict:\n",
    "        if metric not in best_metric:\n",
    "            best_metric[metric] = 0\n",
    "        if metrics_result_dict[metric] > best_metric[metric]:\n",
    "            best_metric[metric] = metrics_result_dict[metric]\n",
    "            console(f\"Best {metric} model updated. Saving the model.\")\n",
    "            torch.save(\n",
    "                model.state_dict(), f\"{BEST_MODEL_BASE_DIR}/best_{metric}_model.pth\"\n",
    "            )\n",
    "\n",
    "    console(f\"Eval results: \")\n",
    "    for metric in metrics_result_dict:\n",
    "        console(f\"{metric}: {metrics_result_dict[metric]:.4f}\")\n",
    "    console(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1733328554280,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "Ccnd4tT2B-xU"
   },
   "outputs": [],
   "source": [
    "from loss import loss_dict\n",
    "\n",
    "loss_fn = loss_dict[LOSS_FN](\n",
    "    item_degree=train_item_degree, reg_strength=reg_strength\n",
    ").loss_fn\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_train_or_test_loop(dataloader):\n",
    "    \"\"\"\n",
    "    run the train dataloader for an epoch\n",
    "    \"\"\"\n",
    "    for _ in dataloader:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 646693,
     "status": "ok",
     "timestamp": 1733329334846,
     "user": {
      "displayName": "신명준",
      "userId": "03564838556384347007"
     },
     "user_tz": -540
    },
    "id": "lzQJQzm6B-xU",
    "outputId": "2606e161-46d2-4eec-f933-ee155501ac57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/605 [00:04<04:18,  2.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mstart_epoch, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     17\u001b[0m     console(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     test_loop(test_dataloader, model, loss_fn, evaluator, epoch)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DO_NEG_SAMPLING:\n",
      "Cell \u001b[0;32mIn[15], line 25\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(train_dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresult, pos_item\u001b[38;5;241m=\u001b[39mpos_item)\n\u001b[1;32m     24\u001b[0m loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_num \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/diversity-enhanced-lightgcn/lib/python3.13/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/diversity-enhanced-lightgcn/lib/python3.13/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/diversity-enhanced-lightgcn/lib/python3.13/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from evaluator import TopKEvaluator\n",
    "\n",
    "evaluator = TopKEvaluator(\n",
    "    TOP_K, METRICS, device=device, item_degree=train_test_item_degree\n",
    ")\n",
    "\n",
    "if config.start_epoch != 1:\n",
    "    # run the train dataloader and test dataloader for start_epoch - 1 times\n",
    "    # to simulate the training process\n",
    "    console(f\"Simulating training and testing for {config.start_epoch - 1} epochs\")\n",
    "    for epoch in tqdm(range(1, config.start_epoch)):\n",
    "        simulated_train_or_test_loop(train_dataloader)\n",
    "        simulated_train_or_test_loop(test_dataloader)\n",
    "    console(\"Simulation done\")\n",
    "\n",
    "for epoch in range(config.start_epoch, EPOCHS + 1):\n",
    "    console(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    if epoch % config.eval_every_n_epochs == 0:\n",
    "        test_loop(test_dataloader, model, loss_fn, evaluator, epoch)\n",
    "\n",
    "    if DO_NEG_SAMPLING:\n",
    "        train_dataloader.dataset.sample_negs()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "diversity-enhanced-lightgcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
